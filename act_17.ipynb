{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "act_17.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYiWzBBx0d_T",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "47c36518-6ffd-4373-da65-4637f80261dd"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f12b90ef-9871-4b3b-a8de-3a65b6d51b13\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f12b90ef-9871-4b3b-a8de-3a65b6d51b13\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Covid_19_data_TM_JE.csv to Covid_19_data_TM_JE (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdXWAxk74B5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "44938122-55ee-4bbd-dc11-90b43facaca5"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('Covid_19_data_TM_JE.csv', delimiter=',')\n",
        "data.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>on_ventilator_cumulative</th>\n",
              "      <th>recovered</th>\n",
              "      <th>x2020_pop</th>\n",
              "      <th>tests_per_pop</th>\n",
              "      <th>deaths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>185</td>\n",
              "      <td>6099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>734002</td>\n",
              "      <td>0.008561</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1796</td>\n",
              "      <td>11282</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4908621</td>\n",
              "      <td>0.002664</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>830</td>\n",
              "      <td>10412</td>\n",
              "      <td>39</td>\n",
              "      <td>97</td>\n",
              "      <td>3038999</td>\n",
              "      <td>0.003699</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2269</td>\n",
              "      <td>25141</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7378494</td>\n",
              "      <td>0.003715</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13438</td>\n",
              "      <td>103095</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39937489</td>\n",
              "      <td>0.002918</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   positive  negative  ...  tests_per_pop  deaths\n",
              "0       185      6099  ...       0.008561       6\n",
              "1      1796     11282  ...       0.002664      45\n",
              "2       830     10412  ...       0.003699      16\n",
              "3      2269     25141  ...       0.003715      64\n",
              "4     13438    103095  ...       0.002918     319\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTuPy7UO4Dtm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "85151c26-ffb8-44e4-bb0a-a6148c4a009b"
      },
      "source": [
        "import numpy as np\n",
        "dataset = np.genfromtxt('Covid_19_data_TM_JE.csv', delimiter=\",\", skip_header = True)\n",
        "np.set_printoptions(formatter = {'float': '{: 0.1f}'.format}) \n",
        "print('')\n",
        "print(dataset.shape)\n",
        "print('')\n",
        "print(dataset[0:5])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(1604, 7)\n",
            "\n",
            "[[ 185.0  6099.0  0.0  0.0  734002.0  0.0  6.0]\n",
            " [ 1796.0  11282.0  0.0  0.0  4908621.0  0.0  45.0]\n",
            " [ 830.0  10412.0  39.0  97.0  3038999.0  0.0  16.0]\n",
            " [ 2269.0  25141.0  0.0  0.0  7378494.0  0.0  64.0]\n",
            " [ 13438.0  103095.0  0.0  0.0  39937489.0  0.0  319.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHFGm67v4K9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fcab65a2-41d0-4229-ec13-b2454e5d14f8"
      },
      "source": [
        "# base\n",
        "index_30percent = int(0.3 * len(dataset[:, 0]))\n",
        "print(index_30percent)\n",
        "print(int(len(dataset[:, 0])))\n",
        "# Split into training and validation\n",
        "XVALID = dataset[:index_30percent, [0, 1, 2, 3, 4, 5]]\n",
        "YVALID = dataset[:index_30percent, 6]\n",
        "XTRAIN = dataset[index_30percent:, [0, 1, 2, 3, 4, 5]]\n",
        "YTRAIN = dataset[index_30percent:, 6]\n",
        "mean = XTRAIN.mean(axis = 0)\n",
        "XTRAIN -= mean\n",
        "std = XTRAIN.std(axis = 0)\n",
        "XTRAIN /= std\n",
        "XVALID -= mean\n",
        "XVALID /= std"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "481\n",
            "1604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J77qCH44sZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a929d80-65da-4eb6-ec08-449bf94a9bd9"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(12, input_dim = 6, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mae', optimizer = 'rmsprop', metrics=['mae'])\n",
        "thing = model.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs = 1000, verbose = 1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 5.1359 - mae: 5.2573 - val_loss: 90.4532 - val_mae: 96.2689\n",
            "Epoch 2/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 5.0406 - mae: 5.1689 - val_loss: 89.1748 - val_mae: 94.9144\n",
            "Epoch 3/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.9837 - mae: 5.1118 - val_loss: 88.3878 - val_mae: 94.0599\n",
            "Epoch 4/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.9370 - mae: 5.0645 - val_loss: 87.5324 - val_mae: 93.1288\n",
            "Epoch 5/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 8.0286 - mae: 5.0143 - val_loss: 86.7472 - val_mae: 92.2732\n",
            "Epoch 6/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.9255 - mae: 4.9714 - val_loss: 86.2444 - val_mae: 91.7211\n",
            "Epoch 7/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.9254 - mae: 4.9232 - val_loss: 85.4692 - val_mae: 90.8745\n",
            "Epoch 8/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.7935 - mae: 4.8694 - val_loss: 84.7962 - val_mae: 90.1424\n",
            "Epoch 9/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4.7000 - mae: 4.8132 - val_loss: 83.9804 - val_mae: 89.2540\n",
            "Epoch 10/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.8264 - mae: 4.7559 - val_loss: 83.0539 - val_mae: 88.2449\n",
            "Epoch 11/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.5885 - mae: 4.6838 - val_loss: 82.2049 - val_mae: 87.3255\n",
            "Epoch 12/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4.5310 - mae: 4.6046 - val_loss: 80.9078 - val_mae: 85.9192\n",
            "Epoch 13/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.4133 - mae: 4.5014 - val_loss: 79.6324 - val_mae: 84.5338\n",
            "Epoch 14/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.3188 - mae: 4.4194 - val_loss: 78.6222 - val_mae: 83.4356\n",
            "Epoch 15/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.2337 - mae: 4.3258 - val_loss: 77.3428 - val_mae: 82.0454\n",
            "Epoch 16/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.1290 - mae: 4.2355 - val_loss: 76.1472 - val_mae: 80.7475\n",
            "Epoch 17/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4.0420 - mae: 4.1432 - val_loss: 74.9749 - val_mae: 79.4766\n",
            "Epoch 18/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.9765 - mae: 4.0441 - val_loss: 73.7142 - val_mae: 78.1096\n",
            "Epoch 19/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.8529 - mae: 3.9524 - val_loss: 72.5296 - val_mae: 76.8312\n",
            "Epoch 20/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.8302 - mae: 3.8667 - val_loss: 71.6939 - val_mae: 75.9400\n",
            "Epoch 21/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.9948 - mae: 3.8042 - val_loss: 70.7278 - val_mae: 74.9056\n",
            "Epoch 22/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.6935 - mae: 3.7335 - val_loss: 69.8963 - val_mae: 74.0281\n",
            "Epoch 23/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.6243 - mae: 3.6870 - val_loss: 69.0966 - val_mae: 73.1828\n",
            "Epoch 24/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.5419 - mae: 3.6334 - val_loss: 68.1220 - val_mae: 72.1438\n",
            "Epoch 25/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.5015 - mae: 3.5919 - val_loss: 67.4271 - val_mae: 71.4143\n",
            "Epoch 26/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.5199 - mae: 3.5583 - val_loss: 66.8711 - val_mae: 70.8276\n",
            "Epoch 27/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.5276 - mae: 3.5239 - val_loss: 66.1653 - val_mae: 70.0837\n",
            "Epoch 28/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.4033 - mae: 3.4910 - val_loss: 65.5198 - val_mae: 69.4115\n",
            "Epoch 29/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3767 - mae: 3.4605 - val_loss: 64.8337 - val_mae: 68.6969\n",
            "Epoch 30/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3985 - mae: 3.4260 - val_loss: 64.2293 - val_mae: 68.0783\n",
            "Epoch 31/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3179 - mae: 3.3947 - val_loss: 63.5328 - val_mae: 67.3541\n",
            "Epoch 32/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3528 - mae: 3.3584 - val_loss: 62.6893 - val_mae: 66.4531\n",
            "Epoch 33/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.2600 - mae: 3.3189 - val_loss: 61.9374 - val_mae: 65.6576\n",
            "Epoch 34/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.2229 - mae: 3.2930 - val_loss: 61.4346 - val_mae: 65.1344\n",
            "Epoch 35/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.1884 - mae: 3.2707 - val_loss: 60.9287 - val_mae: 64.6054\n",
            "Epoch 36/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.2755 - mae: 3.2509 - val_loss: 60.5165 - val_mae: 64.1868\n",
            "Epoch 37/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.1688 - mae: 3.2334 - val_loss: 60.0800 - val_mae: 63.7321\n",
            "Epoch 38/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.1469 - mae: 3.2195 - val_loss: 59.6834 - val_mae: 63.3284\n",
            "Epoch 39/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3571 - mae: 3.1997 - val_loss: 59.3958 - val_mae: 63.0453\n",
            "Epoch 40/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.1027 - mae: 3.1810 - val_loss: 58.8224 - val_mae: 62.4431\n",
            "Epoch 41/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.1332 - mae: 3.1713 - val_loss: 58.4326 - val_mae: 62.0446\n",
            "Epoch 42/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.1076 - mae: 3.1560 - val_loss: 58.0899 - val_mae: 61.6970\n",
            "Epoch 43/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.0819 - mae: 3.1370 - val_loss: 57.5634 - val_mae: 61.1374\n",
            "Epoch 44/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.0517 - mae: 3.1191 - val_loss: 57.0861 - val_mae: 60.6506\n",
            "Epoch 45/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.1138 - mae: 3.1038 - val_loss: 56.8529 - val_mae: 60.4197\n",
            "Epoch 46/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.1595 - mae: 3.0908 - val_loss: 56.2019 - val_mae: 59.7307\n",
            "Epoch 47/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.9982 - mae: 3.0719 - val_loss: 55.7121 - val_mae: 59.2241\n",
            "Epoch 48/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3239 - mae: 3.0656 - val_loss: 55.7548 - val_mae: 59.2950\n",
            "Epoch 49/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.9691 - mae: 3.0448 - val_loss: 55.2111 - val_mae: 58.7280\n",
            "Epoch 50/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.9616 - mae: 3.0303 - val_loss: 54.8080 - val_mae: 58.3018\n",
            "Epoch 51/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.9973 - mae: 3.0182 - val_loss: 54.6084 - val_mae: 58.0951\n",
            "Epoch 52/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.9310 - mae: 3.0066 - val_loss: 54.3974 - val_mae: 57.8768\n",
            "Epoch 53/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.9307 - mae: 2.9950 - val_loss: 53.9494 - val_mae: 57.3968\n",
            "Epoch 54/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.9071 - mae: 2.9821 - val_loss: 53.6757 - val_mae: 57.1085\n",
            "Epoch 55/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3510 - mae: 2.9738 - val_loss: 53.3582 - val_mae: 56.7719\n",
            "Epoch 56/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.8828 - mae: 2.9570 - val_loss: 53.1041 - val_mae: 56.5023\n",
            "Epoch 57/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.8926 - mae: 2.9527 - val_loss: 52.8241 - val_mae: 56.2061\n",
            "Epoch 58/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.4866 - mae: 2.9383 - val_loss: 52.7409 - val_mae: 56.1181\n",
            "Epoch 59/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.8596 - mae: 2.9334 - val_loss: 52.4325 - val_mae: 55.7936\n",
            "Epoch 60/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.8458 - mae: 2.9193 - val_loss: 52.1041 - val_mae: 55.4471\n",
            "Epoch 61/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.3023 - mae: 2.9113 - val_loss: 52.0665 - val_mae: 55.4071\n",
            "Epoch 62/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.8288 - mae: 2.9018 - val_loss: 51.8667 - val_mae: 55.1997\n",
            "Epoch 63/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.8358 - mae: 2.8938 - val_loss: 51.5397 - val_mae: 54.8554\n",
            "Epoch 64/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.8066 - mae: 2.8791 - val_loss: 51.1349 - val_mae: 54.4274\n",
            "Epoch 65/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.8019 - mae: 2.8721 - val_loss: 50.9722 - val_mae: 54.2550\n",
            "Epoch 66/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.8000 - mae: 2.8582 - val_loss: 50.6154 - val_mae: 53.8705\n",
            "Epoch 67/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.9872 - mae: 2.8456 - val_loss: 50.2674 - val_mae: 53.5035\n",
            "Epoch 68/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7740 - mae: 2.8301 - val_loss: 49.8218 - val_mae: 53.0285\n",
            "Epoch 69/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7569 - mae: 2.8195 - val_loss: 49.5331 - val_mae: 52.7222\n",
            "Epoch 70/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7674 - mae: 2.8105 - val_loss: 49.3836 - val_mae: 52.5607\n",
            "Epoch 71/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7943 - mae: 2.7986 - val_loss: 49.0006 - val_mae: 52.1564\n",
            "Epoch 72/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.1880 - mae: 2.7962 - val_loss: 48.7453 - val_mae: 51.8835\n",
            "Epoch 73/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7352 - mae: 2.7828 - val_loss: 48.7144 - val_mae: 51.8500\n",
            "Epoch 74/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.7162 - mae: 2.7861 - val_loss: 48.6078 - val_mae: 51.7369\n",
            "Epoch 75/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.7065 - mae: 2.7764 - val_loss: 48.4683 - val_mae: 51.5895\n",
            "Epoch 76/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7017 - mae: 2.7714 - val_loss: 48.3553 - val_mae: 51.4687\n",
            "Epoch 77/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7609 - mae: 2.7620 - val_loss: 48.1425 - val_mae: 51.2448\n",
            "Epoch 78/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7675 - mae: 2.7532 - val_loss: 48.0365 - val_mae: 51.1284\n",
            "Epoch 79/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7342 - mae: 2.7460 - val_loss: 48.0304 - val_mae: 51.1219\n",
            "Epoch 80/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3.2495 - mae: 2.7404 - val_loss: 47.6268 - val_mae: 50.6955\n",
            "Epoch 81/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.6833 - mae: 2.7300 - val_loss: 47.5120 - val_mae: 50.5715\n",
            "Epoch 82/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.7984 - mae: 2.7281 - val_loss: 47.5759 - val_mae: 50.6381\n",
            "Epoch 83/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.6628 - mae: 2.7203 - val_loss: 47.3434 - val_mae: 50.3942\n",
            "Epoch 84/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.8981 - mae: 2.7179 - val_loss: 47.1353 - val_mae: 50.1712\n",
            "Epoch 85/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.6386 - mae: 2.7067 - val_loss: 46.8495 - val_mae: 49.8678\n",
            "Epoch 86/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6340 - mae: 2.7007 - val_loss: 46.5789 - val_mae: 49.5800\n",
            "Epoch 87/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.6284 - mae: 2.6938 - val_loss: 46.4309 - val_mae: 49.4202\n",
            "Epoch 88/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6202 - mae: 2.6878 - val_loss: 46.2194 - val_mae: 49.1962\n",
            "Epoch 89/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.6150 - mae: 2.6818 - val_loss: 46.0437 - val_mae: 49.0095\n",
            "Epoch 90/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.7108 - mae: 2.6742 - val_loss: 45.9011 - val_mae: 48.8590\n",
            "Epoch 91/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.6111 - mae: 2.6631 - val_loss: 46.1873 - val_mae: 49.1628\n",
            "Epoch 92/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.1489 - mae: 2.6727 - val_loss: 46.4181 - val_mae: 49.4077\n",
            "Epoch 93/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6782 - mae: 2.6625 - val_loss: 46.0809 - val_mae: 49.0497\n",
            "Epoch 94/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.6173 - mae: 2.6567 - val_loss: 45.8603 - val_mae: 48.8151\n",
            "Epoch 95/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.6360 - mae: 2.6479 - val_loss: 45.7096 - val_mae: 48.6545\n",
            "Epoch 96/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5864 - mae: 2.6456 - val_loss: 46.1460 - val_mae: 49.1166\n",
            "Epoch 97/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.9295 - mae: 2.6463 - val_loss: 45.7447 - val_mae: 48.6921\n",
            "Epoch 98/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5705 - mae: 2.6354 - val_loss: 45.5545 - val_mae: 48.4879\n",
            "Epoch 99/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5719 - mae: 2.6369 - val_loss: 45.9547 - val_mae: 48.9121\n",
            "Epoch 100/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6473 - mae: 2.6251 - val_loss: 46.3431 - val_mae: 49.3222\n",
            "Epoch 101/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6594 - mae: 2.6302 - val_loss: 45.8827 - val_mae: 48.8350\n",
            "Epoch 102/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5930 - mae: 2.6315 - val_loss: 45.8453 - val_mae: 48.7952\n",
            "Epoch 103/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5540 - mae: 2.6185 - val_loss: 45.5823 - val_mae: 48.5143\n",
            "Epoch 104/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.6216 - mae: 2.6145 - val_loss: 45.9299 - val_mae: 48.8843\n",
            "Epoch 105/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5479 - mae: 2.6137 - val_loss: 45.6147 - val_mae: 48.5497\n",
            "Epoch 106/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6130 - mae: 2.6085 - val_loss: 45.4793 - val_mae: 48.4080\n",
            "Epoch 107/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7371 - mae: 2.6026 - val_loss: 46.0352 - val_mae: 48.9936\n",
            "Epoch 108/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6540 - mae: 2.5971 - val_loss: 46.1037 - val_mae: 49.0650\n",
            "Epoch 109/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3.0627 - mae: 2.5940 - val_loss: 45.4292 - val_mae: 48.3532\n",
            "Epoch 110/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.8360 - mae: 2.5928 - val_loss: 45.2806 - val_mae: 48.1975\n",
            "Epoch 111/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5699 - mae: 2.5972 - val_loss: 45.7086 - val_mae: 48.6481\n",
            "Epoch 112/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6758 - mae: 2.5900 - val_loss: 45.5964 - val_mae: 48.5294\n",
            "Epoch 113/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5432 - mae: 2.5817 - val_loss: 46.1649 - val_mae: 49.1305\n",
            "Epoch 114/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5253 - mae: 2.5845 - val_loss: 45.7865 - val_mae: 48.7295\n",
            "Epoch 115/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6526 - mae: 2.5751 - val_loss: 45.7190 - val_mae: 48.6554\n",
            "Epoch 116/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5240 - mae: 2.5719 - val_loss: 45.4290 - val_mae: 48.3466\n",
            "Epoch 117/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5059 - mae: 2.5698 - val_loss: 45.8522 - val_mae: 48.7944\n",
            "Epoch 118/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6031 - mae: 2.5630 - val_loss: 45.5737 - val_mae: 48.4994\n",
            "Epoch 119/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5503 - mae: 2.5611 - val_loss: 45.8069 - val_mae: 48.7465\n",
            "Epoch 120/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5006 - mae: 2.5566 - val_loss: 45.4041 - val_mae: 48.3194\n",
            "Epoch 121/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4929 - mae: 2.5498 - val_loss: 45.3169 - val_mae: 48.2279\n",
            "Epoch 122/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.7223 - mae: 2.5501 - val_loss: 45.5399 - val_mae: 48.4632\n",
            "Epoch 123/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4890 - mae: 2.5446 - val_loss: 45.9053 - val_mae: 48.8500\n",
            "Epoch 124/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.7372 - mae: 2.5441 - val_loss: 45.4038 - val_mae: 48.3187\n",
            "Epoch 125/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5113 - mae: 2.5352 - val_loss: 45.2731 - val_mae: 48.1808\n",
            "Epoch 126/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4863 - mae: 2.5359 - val_loss: 45.6887 - val_mae: 48.6205\n",
            "Epoch 127/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4654 - mae: 2.5289 - val_loss: 45.2119 - val_mae: 48.1142\n",
            "Epoch 128/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5380 - mae: 2.5208 - val_loss: 44.9791 - val_mae: 47.8658\n",
            "Epoch 129/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4819 - mae: 2.5277 - val_loss: 45.4331 - val_mae: 48.3431\n",
            "Epoch 130/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4609 - mae: 2.5178 - val_loss: 45.8679 - val_mae: 48.8036\n",
            "Epoch 131/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5467 - mae: 2.5119 - val_loss: 45.4359 - val_mae: 48.3460\n",
            "Epoch 132/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6415 - mae: 2.5021 - val_loss: 44.7980 - val_mae: 47.6683\n",
            "Epoch 133/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4497 - mae: 2.5128 - val_loss: 45.2221 - val_mae: 48.1176\n",
            "Epoch 134/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.4552 - mae: 2.5030 - val_loss: 45.7148 - val_mae: 48.6375\n",
            "Epoch 135/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4322 - mae: 2.4942 - val_loss: 45.3411 - val_mae: 48.2395\n",
            "Epoch 136/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4355 - mae: 2.4983 - val_loss: 45.5456 - val_mae: 48.4568\n",
            "Epoch 137/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4740 - mae: 2.4867 - val_loss: 45.8638 - val_mae: 48.7968\n",
            "Epoch 138/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6754 - mae: 2.4854 - val_loss: 45.5007 - val_mae: 48.4123\n",
            "Epoch 139/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4224 - mae: 2.4794 - val_loss: 45.7077 - val_mae: 48.6298\n",
            "Epoch 140/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4161 - mae: 2.4742 - val_loss: 45.5579 - val_mae: 48.4711\n",
            "Epoch 141/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4303 - mae: 2.4695 - val_loss: 45.8234 - val_mae: 48.7528\n",
            "Epoch 142/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4980 - mae: 2.4641 - val_loss: 45.6702 - val_mae: 48.5883\n",
            "Epoch 143/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3977 - mae: 2.4593 - val_loss: 46.0440 - val_mae: 48.9837\n",
            "Epoch 144/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3996 - mae: 2.4589 - val_loss: 45.8135 - val_mae: 48.7347\n",
            "Epoch 145/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6508 - mae: 2.4476 - val_loss: 45.8748 - val_mae: 48.8031\n",
            "Epoch 146/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5032 - mae: 2.4548 - val_loss: 45.9417 - val_mae: 48.8777\n",
            "Epoch 147/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.6393 - mae: 2.4389 - val_loss: 46.4058 - val_mae: 49.3671\n",
            "Epoch 148/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3854 - mae: 2.4467 - val_loss: 46.1007 - val_mae: 49.0449\n",
            "Epoch 149/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.4300 - mae: 2.4373 - val_loss: 45.5956 - val_mae: 48.5108\n",
            "Epoch 150/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3688 - mae: 2.4271 - val_loss: 45.3358 - val_mae: 48.2326\n",
            "Epoch 151/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3692 - mae: 2.4304 - val_loss: 45.6126 - val_mae: 48.5255\n",
            "Epoch 152/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4433 - mae: 2.4191 - val_loss: 45.9623 - val_mae: 48.8987\n",
            "Epoch 153/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5544 - mae: 2.4152 - val_loss: 45.4507 - val_mae: 48.3544\n",
            "Epoch 154/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3745 - mae: 2.4152 - val_loss: 45.9675 - val_mae: 48.9012\n",
            "Epoch 155/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3657 - mae: 2.4041 - val_loss: 46.0448 - val_mae: 48.9877\n",
            "Epoch 156/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3415 - mae: 2.4017 - val_loss: 45.6702 - val_mae: 48.5897\n",
            "Epoch 157/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3365 - mae: 2.3959 - val_loss: 45.3574 - val_mae: 48.2525\n",
            "Epoch 158/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3488 - mae: 2.4001 - val_loss: 45.7518 - val_mae: 48.6705\n",
            "Epoch 159/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3481 - mae: 2.3902 - val_loss: 45.9681 - val_mae: 48.9009\n",
            "Epoch 160/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3305 - mae: 2.3880 - val_loss: 45.5677 - val_mae: 48.4741\n",
            "Epoch 161/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3248 - mae: 2.3848 - val_loss: 46.0234 - val_mae: 48.9560\n",
            "Epoch 162/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3819 - mae: 2.3872 - val_loss: 45.7740 - val_mae: 48.6930\n",
            "Epoch 163/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3337 - mae: 2.3719 - val_loss: 45.2538 - val_mae: 48.1417\n",
            "Epoch 164/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.5406 - mae: 2.3757 - val_loss: 45.9383 - val_mae: 48.8693\n",
            "Epoch 165/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3691 - mae: 2.3724 - val_loss: 45.9644 - val_mae: 48.8980\n",
            "Epoch 166/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3226 - mae: 2.3662 - val_loss: 46.0939 - val_mae: 49.0326\n",
            "Epoch 167/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3235 - mae: 2.3670 - val_loss: 45.5594 - val_mae: 48.4657\n",
            "Epoch 168/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3067 - mae: 2.3618 - val_loss: 45.8624 - val_mae: 48.7843\n",
            "Epoch 169/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3655 - mae: 2.3561 - val_loss: 45.2315 - val_mae: 48.1198\n",
            "Epoch 170/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2992 - mae: 2.3554 - val_loss: 45.3868 - val_mae: 48.2798\n",
            "Epoch 171/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2973 - mae: 2.3502 - val_loss: 45.5609 - val_mae: 48.4647\n",
            "Epoch 172/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.4796 - mae: 2.3399 - val_loss: 44.5869 - val_mae: 47.4342\n",
            "Epoch 173/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3042 - mae: 2.3464 - val_loss: 44.9711 - val_mae: 47.8421\n",
            "Epoch 174/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3281 - mae: 2.3429 - val_loss: 45.1311 - val_mae: 48.0141\n",
            "Epoch 175/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2856 - mae: 2.3350 - val_loss: 45.2124 - val_mae: 48.0997\n",
            "Epoch 176/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2683 - mae: 2.3268 - val_loss: 44.5947 - val_mae: 47.4428\n",
            "Epoch 177/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3412 - mae: 2.3353 - val_loss: 44.8833 - val_mae: 47.7457\n",
            "Epoch 178/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2785 - mae: 2.3267 - val_loss: 45.1422 - val_mae: 48.0187\n",
            "Epoch 179/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2661 - mae: 2.3242 - val_loss: 44.6310 - val_mae: 47.4785\n",
            "Epoch 180/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3738 - mae: 2.3231 - val_loss: 44.9536 - val_mae: 47.8208\n",
            "Epoch 181/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2563 - mae: 2.3134 - val_loss: 45.2761 - val_mae: 48.1608\n",
            "Epoch 182/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2599 - mae: 2.3180 - val_loss: 44.5876 - val_mae: 47.4354\n",
            "Epoch 183/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2645 - mae: 2.3073 - val_loss: 45.0141 - val_mae: 47.8830\n",
            "Epoch 184/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2607 - mae: 2.3078 - val_loss: 45.2689 - val_mae: 48.1532\n",
            "Epoch 185/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4458 - mae: 2.3121 - val_loss: 44.5986 - val_mae: 47.4444\n",
            "Epoch 186/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2646 - mae: 2.3047 - val_loss: 44.7670 - val_mae: 47.6247\n",
            "Epoch 187/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2767 - mae: 2.2994 - val_loss: 44.4002 - val_mae: 47.2327\n",
            "Epoch 188/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2449 - mae: 2.3028 - val_loss: 44.4856 - val_mae: 47.3236\n",
            "Epoch 189/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3237 - mae: 2.2979 - val_loss: 44.5328 - val_mae: 47.3754\n",
            "Epoch 190/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2366 - mae: 2.2904 - val_loss: 44.1545 - val_mae: 46.9696\n",
            "Epoch 191/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2408 - mae: 2.2941 - val_loss: 44.1623 - val_mae: 46.9790\n",
            "Epoch 192/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2350 - mae: 2.2923 - val_loss: 44.2249 - val_mae: 47.0468\n",
            "Epoch 193/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3601 - mae: 2.2899 - val_loss: 44.5497 - val_mae: 47.3897\n",
            "Epoch 194/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.5490 - mae: 2.2862 - val_loss: 44.2567 - val_mae: 47.0830\n",
            "Epoch 195/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2434 - mae: 2.2848 - val_loss: 44.2278 - val_mae: 47.0535\n",
            "Epoch 196/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2496 - mae: 2.2818 - val_loss: 44.2791 - val_mae: 47.1053\n",
            "Epoch 197/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2249 - mae: 2.2790 - val_loss: 44.0534 - val_mae: 46.8646\n",
            "Epoch 198/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2176 - mae: 2.2746 - val_loss: 43.8728 - val_mae: 46.6726\n",
            "Epoch 199/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2224 - mae: 2.2796 - val_loss: 43.9194 - val_mae: 46.7243\n",
            "Epoch 200/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2364 - mae: 2.2778 - val_loss: 43.8730 - val_mae: 46.6754\n",
            "Epoch 201/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2114 - mae: 2.2681 - val_loss: 43.1817 - val_mae: 45.9429\n",
            "Epoch 202/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2185 - mae: 2.2755 - val_loss: 43.3100 - val_mae: 46.0802\n",
            "Epoch 203/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2318 - mae: 2.2716 - val_loss: 43.8417 - val_mae: 46.6430\n",
            "Epoch 204/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2308 - mae: 2.2647 - val_loss: 43.1739 - val_mae: 45.9344\n",
            "Epoch 205/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2161 - mae: 2.2630 - val_loss: 43.0549 - val_mae: 45.8050\n",
            "Epoch 206/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2340 - mae: 2.2711 - val_loss: 43.1012 - val_mae: 45.8600\n",
            "Epoch 207/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2389 - mae: 2.2606 - val_loss: 43.9759 - val_mae: 46.7802\n",
            "Epoch 208/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2047 - mae: 2.2615 - val_loss: 43.3520 - val_mae: 46.1224\n",
            "Epoch 209/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3222 - mae: 2.2615 - val_loss: 43.4130 - val_mae: 46.1882\n",
            "Epoch 210/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2341 - mae: 2.2556 - val_loss: 43.8407 - val_mae: 46.6456\n",
            "Epoch 211/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.5755 - mae: 2.2500 - val_loss: 42.5914 - val_mae: 45.3211\n",
            "Epoch 212/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2087 - mae: 2.2651 - val_loss: 43.1911 - val_mae: 45.9476\n",
            "Epoch 213/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1997 - mae: 2.2556 - val_loss: 43.6068 - val_mae: 46.3921\n",
            "Epoch 214/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1947 - mae: 2.2510 - val_loss: 43.7433 - val_mae: 46.5377\n",
            "Epoch 215/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3608 - mae: 2.2473 - val_loss: 44.1277 - val_mae: 46.9450\n",
            "Epoch 216/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2080 - mae: 2.2541 - val_loss: 43.4872 - val_mae: 46.2680\n",
            "Epoch 217/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1890 - mae: 2.2454 - val_loss: 43.6046 - val_mae: 46.3919\n",
            "Epoch 218/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1887 - mae: 2.2450 - val_loss: 43.3853 - val_mae: 46.1598\n",
            "Epoch 219/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2003 - mae: 2.2432 - val_loss: 43.3467 - val_mae: 46.1242\n",
            "Epoch 220/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1866 - mae: 2.2412 - val_loss: 43.1708 - val_mae: 45.9319\n",
            "Epoch 221/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2052 - mae: 2.2388 - val_loss: 43.3781 - val_mae: 46.1523\n",
            "Epoch 222/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3054 - mae: 2.2335 - val_loss: 43.5798 - val_mae: 46.3691\n",
            "Epoch 223/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1791 - mae: 2.2351 - val_loss: 43.2279 - val_mae: 45.9946\n",
            "Epoch 224/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1748 - mae: 2.2307 - val_loss: 43.1487 - val_mae: 45.9106\n",
            "Epoch 225/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1826 - mae: 2.2295 - val_loss: 43.3266 - val_mae: 46.0974\n",
            "Epoch 226/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1765 - mae: 2.2264 - val_loss: 42.8998 - val_mae: 45.6506\n",
            "Epoch 227/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1729 - mae: 2.2289 - val_loss: 43.4044 - val_mae: 46.1842\n",
            "Epoch 228/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1697 - mae: 2.2254 - val_loss: 43.1289 - val_mae: 45.8900\n",
            "Epoch 229/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1740 - mae: 2.2225 - val_loss: 43.2400 - val_mae: 46.0110\n",
            "Epoch 230/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3021 - mae: 2.2161 - val_loss: 43.0576 - val_mae: 45.8189\n",
            "Epoch 231/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3658 - mae: 2.2177 - val_loss: 42.7988 - val_mae: 45.5440\n",
            "Epoch 232/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2207 - mae: 2.2157 - val_loss: 43.3251 - val_mae: 46.1013\n",
            "Epoch 233/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2269 - mae: 2.2154 - val_loss: 43.0797 - val_mae: 45.8374\n",
            "Epoch 234/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2604 - mae: 2.2099 - val_loss: 42.8546 - val_mae: 45.5951\n",
            "Epoch 235/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1529 - mae: 2.2082 - val_loss: 42.8587 - val_mae: 45.6021\n",
            "Epoch 236/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2437 - mae: 2.2030 - val_loss: 43.5930 - val_mae: 46.3792\n",
            "Epoch 237/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1533 - mae: 2.2027 - val_loss: 42.6407 - val_mae: 45.3777\n",
            "Epoch 238/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1578 - mae: 2.2034 - val_loss: 43.3005 - val_mae: 46.0726\n",
            "Epoch 239/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1807 - mae: 2.2033 - val_loss: 42.9233 - val_mae: 45.6723\n",
            "Epoch 240/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3265 - mae: 2.1969 - val_loss: 43.6005 - val_mae: 46.3873\n",
            "Epoch 241/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1479 - mae: 2.2025 - val_loss: 42.9922 - val_mae: 45.7461\n",
            "Epoch 242/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1703 - mae: 2.1949 - val_loss: 43.0347 - val_mae: 45.7990\n",
            "Epoch 243/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1506 - mae: 2.1906 - val_loss: 42.9037 - val_mae: 45.6531\n",
            "Epoch 244/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1752 - mae: 2.1851 - val_loss: 43.3416 - val_mae: 46.1180\n",
            "Epoch 245/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1483 - mae: 2.1872 - val_loss: 42.4721 - val_mae: 45.2021\n",
            "Epoch 246/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1818 - mae: 2.1851 - val_loss: 42.9902 - val_mae: 45.7473\n",
            "Epoch 247/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1335 - mae: 2.1809 - val_loss: 42.9623 - val_mae: 45.7184\n",
            "Epoch 248/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1249 - mae: 2.1778 - val_loss: 42.7401 - val_mae: 45.4779\n",
            "Epoch 249/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4202 - mae: 2.1740 - val_loss: 42.4400 - val_mae: 45.1699\n",
            "Epoch 250/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1311 - mae: 2.1694 - val_loss: 42.3345 - val_mae: 45.0507\n",
            "Epoch 251/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1129 - mae: 2.1627 - val_loss: 42.0788 - val_mae: 44.7790\n",
            "Epoch 252/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1188 - mae: 2.1654 - val_loss: 42.7563 - val_mae: 45.4910\n",
            "Epoch 253/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1185 - mae: 2.1581 - val_loss: 42.5508 - val_mae: 45.2776\n",
            "Epoch 254/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1392 - mae: 2.1535 - val_loss: 42.2145 - val_mae: 44.9160\n",
            "Epoch 255/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0975 - mae: 2.1504 - val_loss: 42.0503 - val_mae: 44.7471\n",
            "Epoch 256/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1104 - mae: 2.1535 - val_loss: 42.4571 - val_mae: 45.1839\n",
            "Epoch 257/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0894 - mae: 2.1430 - val_loss: 41.9858 - val_mae: 44.6815\n",
            "Epoch 258/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1004 - mae: 2.1412 - val_loss: 42.7229 - val_mae: 45.4595\n",
            "Epoch 259/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0901 - mae: 2.1384 - val_loss: 42.1434 - val_mae: 44.8481\n",
            "Epoch 260/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0972 - mae: 2.1428 - val_loss: 42.4310 - val_mae: 45.1518\n",
            "Epoch 261/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0828 - mae: 2.1364 - val_loss: 41.9343 - val_mae: 44.6266\n",
            "Epoch 262/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2536 - mae: 2.1347 - val_loss: 42.8059 - val_mae: 45.5423\n",
            "Epoch 263/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0811 - mae: 2.1348 - val_loss: 42.5071 - val_mae: 45.2259\n",
            "Epoch 264/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1673 - mae: 2.1288 - val_loss: 42.2095 - val_mae: 44.9165\n",
            "Epoch 265/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0767 - mae: 2.1297 - val_loss: 42.4568 - val_mae: 45.1789\n",
            "Epoch 266/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0659 - mae: 2.1192 - val_loss: 42.7670 - val_mae: 45.5012\n",
            "Epoch 267/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0606 - mae: 2.1104 - val_loss: 41.6634 - val_mae: 44.3417\n",
            "Epoch 268/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0771 - mae: 2.1213 - val_loss: 42.4214 - val_mae: 45.1282\n",
            "Epoch 269/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4723 - mae: 2.1196 - val_loss: 41.7647 - val_mae: 44.4406\n",
            "Epoch 270/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3521 - mae: 2.1151 - val_loss: 42.1986 - val_mae: 44.9022\n",
            "Epoch 271/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2534 - mae: 2.1154 - val_loss: 42.0323 - val_mae: 44.7212\n",
            "Epoch 272/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3436 - mae: 2.1089 - val_loss: 41.6087 - val_mae: 44.2769\n",
            "Epoch 273/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0537 - mae: 2.1061 - val_loss: 42.2138 - val_mae: 44.9193\n",
            "Epoch 274/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0971 - mae: 2.1049 - val_loss: 41.6003 - val_mae: 44.2687\n",
            "Epoch 275/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0576 - mae: 2.1033 - val_loss: 42.1968 - val_mae: 44.8859\n",
            "Epoch 276/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0650 - mae: 2.1001 - val_loss: 41.7920 - val_mae: 44.4656\n",
            "Epoch 277/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0537 - mae: 2.0975 - val_loss: 41.9793 - val_mae: 44.6696\n",
            "Epoch 278/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0396 - mae: 2.0920 - val_loss: 42.4020 - val_mae: 45.1174\n",
            "Epoch 279/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0489 - mae: 2.0963 - val_loss: 42.0885 - val_mae: 44.7837\n",
            "Epoch 280/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0390 - mae: 2.0892 - val_loss: 41.6044 - val_mae: 44.2738\n",
            "Epoch 281/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0318 - mae: 2.0842 - val_loss: 42.2942 - val_mae: 44.9972\n",
            "Epoch 282/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0795 - mae: 2.0865 - val_loss: 41.8700 - val_mae: 44.5555\n",
            "Epoch 283/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.3349 - mae: 2.0842 - val_loss: 41.4819 - val_mae: 44.1458\n",
            "Epoch 284/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0256 - mae: 2.0778 - val_loss: 41.7612 - val_mae: 44.4382\n",
            "Epoch 285/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1156 - mae: 2.0776 - val_loss: 42.0473 - val_mae: 44.7469\n",
            "Epoch 286/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.3393 - mae: 2.0774 - val_loss: 41.7159 - val_mae: 44.3850\n",
            "Epoch 287/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0230 - mae: 2.0672 - val_loss: 41.7553 - val_mae: 44.4317\n",
            "Epoch 288/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0559 - mae: 2.0718 - val_loss: 41.3883 - val_mae: 44.0332\n",
            "Epoch 289/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0791 - mae: 2.0684 - val_loss: 42.2596 - val_mae: 44.9442\n",
            "Epoch 290/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0249 - mae: 2.0725 - val_loss: 41.8686 - val_mae: 44.5332\n",
            "Epoch 291/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2812 - mae: 2.0665 - val_loss: 41.5541 - val_mae: 44.1999\n",
            "Epoch 292/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2503 - mae: 2.0628 - val_loss: 42.3400 - val_mae: 45.0351\n",
            "Epoch 293/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0645 - mae: 2.0585 - val_loss: 41.0482 - val_mae: 43.6762\n",
            "Epoch 294/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0552 - mae: 2.0611 - val_loss: 42.0745 - val_mae: 44.7514\n",
            "Epoch 295/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0089 - mae: 2.0603 - val_loss: 41.6793 - val_mae: 44.3402\n",
            "Epoch 296/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0027 - mae: 2.0536 - val_loss: 41.7084 - val_mae: 44.3733\n",
            "Epoch 297/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0240 - mae: 2.0554 - val_loss: 41.4157 - val_mae: 44.0634\n",
            "Epoch 298/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0320 - mae: 2.0473 - val_loss: 41.9139 - val_mae: 44.5896\n",
            "Epoch 299/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9958 - mae: 2.0472 - val_loss: 41.6337 - val_mae: 44.2828\n",
            "Epoch 300/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9984 - mae: 2.0475 - val_loss: 41.2884 - val_mae: 43.9189\n",
            "Epoch 301/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9921 - mae: 2.0432 - val_loss: 41.7760 - val_mae: 44.4413\n",
            "Epoch 302/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9868 - mae: 2.0343 - val_loss: 41.0810 - val_mae: 43.7008\n",
            "Epoch 303/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0324 - mae: 2.0449 - val_loss: 41.5489 - val_mae: 44.2107\n",
            "Epoch 304/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0041 - mae: 2.0422 - val_loss: 41.4165 - val_mae: 44.0692\n",
            "Epoch 305/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9862 - mae: 2.0349 - val_loss: 41.8834 - val_mae: 44.5501\n",
            "Epoch 306/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9865 - mae: 2.0336 - val_loss: 41.5005 - val_mae: 44.1490\n",
            "Epoch 307/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9877 - mae: 2.0325 - val_loss: 41.1678 - val_mae: 43.7871\n",
            "Epoch 308/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9805 - mae: 2.0314 - val_loss: 41.7579 - val_mae: 44.4196\n",
            "Epoch 309/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9803 - mae: 2.0283 - val_loss: 40.9681 - val_mae: 43.5866\n",
            "Epoch 310/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9924 - mae: 2.0351 - val_loss: 41.4279 - val_mae: 44.0652\n",
            "Epoch 311/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9724 - mae: 2.0232 - val_loss: 41.4491 - val_mae: 44.0942\n",
            "Epoch 312/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9741 - mae: 2.0211 - val_loss: 41.8766 - val_mae: 44.5453\n",
            "Epoch 313/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1181 - mae: 2.0257 - val_loss: 41.5892 - val_mae: 44.2393\n",
            "Epoch 314/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9773 - mae: 2.0161 - val_loss: 41.2620 - val_mae: 43.8827\n",
            "Epoch 315/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9616 - mae: 2.0119 - val_loss: 41.2028 - val_mae: 43.8371\n",
            "Epoch 316/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9658 - mae: 2.0159 - val_loss: 41.6336 - val_mae: 44.2921\n",
            "Epoch 317/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0265 - mae: 2.0188 - val_loss: 41.4570 - val_mae: 44.1009\n",
            "Epoch 318/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9911 - mae: 2.0024 - val_loss: 42.0674 - val_mae: 44.7445\n",
            "Epoch 319/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9987 - mae: 2.0185 - val_loss: 41.3332 - val_mae: 43.9835\n",
            "Epoch 320/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1597 - mae: 2.0115 - val_loss: 41.2127 - val_mae: 43.8395\n",
            "Epoch 321/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9634 - mae: 2.0139 - val_loss: 41.1667 - val_mae: 43.7926\n",
            "Epoch 322/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9555 - mae: 2.0048 - val_loss: 41.2388 - val_mae: 43.8731\n",
            "Epoch 323/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9996 - mae: 2.0050 - val_loss: 40.9366 - val_mae: 43.5507\n",
            "Epoch 324/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9520 - mae: 2.0020 - val_loss: 41.4868 - val_mae: 44.1283\n",
            "Epoch 325/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9576 - mae: 2.0049 - val_loss: 41.1661 - val_mae: 43.7814\n",
            "Epoch 326/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9578 - mae: 2.0021 - val_loss: 41.2624 - val_mae: 43.8877\n",
            "Epoch 327/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9484 - mae: 1.9978 - val_loss: 41.5268 - val_mae: 44.1731\n",
            "Epoch 328/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0369 - mae: 2.0038 - val_loss: 41.2420 - val_mae: 43.8632\n",
            "Epoch 329/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9540 - mae: 1.9949 - val_loss: 41.3706 - val_mae: 44.0117\n",
            "Epoch 330/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9482 - mae: 1.9937 - val_loss: 41.1414 - val_mae: 43.7673\n",
            "Epoch 331/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9665 - mae: 1.9940 - val_loss: 41.2391 - val_mae: 43.8715\n",
            "Epoch 332/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9408 - mae: 1.9904 - val_loss: 41.5655 - val_mae: 44.2052\n",
            "Epoch 333/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9400 - mae: 1.9899 - val_loss: 40.8373 - val_mae: 43.4396\n",
            "Epoch 334/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9506 - mae: 1.9905 - val_loss: 41.3700 - val_mae: 44.0173\n",
            "Epoch 335/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.2540 - mae: 1.9860 - val_loss: 40.6676 - val_mae: 43.2673\n",
            "Epoch 336/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1240 - mae: 1.9900 - val_loss: 41.0776 - val_mae: 43.6868\n",
            "Epoch 337/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9321 - mae: 1.9802 - val_loss: 41.5533 - val_mae: 44.1866\n",
            "Epoch 338/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0579 - mae: 1.9827 - val_loss: 41.1782 - val_mae: 43.7861\n",
            "Epoch 339/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9340 - mae: 1.9780 - val_loss: 41.3481 - val_mae: 43.9638\n",
            "Epoch 340/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9534 - mae: 1.9802 - val_loss: 41.0424 - val_mae: 43.6549\n",
            "Epoch 341/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9283 - mae: 1.9712 - val_loss: 41.0293 - val_mae: 43.6482\n",
            "Epoch 342/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9639 - mae: 1.9801 - val_loss: 40.9816 - val_mae: 43.5989\n",
            "Epoch 343/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9309 - mae: 1.9751 - val_loss: 41.3897 - val_mae: 44.0169\n",
            "Epoch 344/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9261 - mae: 1.9704 - val_loss: 41.5044 - val_mae: 44.1249\n",
            "Epoch 345/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9203 - mae: 1.9697 - val_loss: 40.8741 - val_mae: 43.4656\n",
            "Epoch 346/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9407 - mae: 1.9704 - val_loss: 41.2641 - val_mae: 43.8770\n",
            "Epoch 347/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9479 - mae: 1.9663 - val_loss: 40.9295 - val_mae: 43.5350\n",
            "Epoch 348/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9404 - mae: 1.9628 - val_loss: 40.9145 - val_mae: 43.5201\n",
            "Epoch 349/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9194 - mae: 1.9687 - val_loss: 41.3429 - val_mae: 43.9517\n",
            "Epoch 350/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9217 - mae: 1.9626 - val_loss: 41.1199 - val_mae: 43.7176\n",
            "Epoch 351/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9248 - mae: 1.9606 - val_loss: 40.9455 - val_mae: 43.5418\n",
            "Epoch 352/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.2760 - mae: 1.9581 - val_loss: 41.2125 - val_mae: 43.8326\n",
            "Epoch 353/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9619 - mae: 1.9530 - val_loss: 40.9376 - val_mae: 43.5386\n",
            "Epoch 354/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9102 - mae: 1.9559 - val_loss: 40.8175 - val_mae: 43.4000\n",
            "Epoch 355/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9176 - mae: 1.9583 - val_loss: 40.8789 - val_mae: 43.4684\n",
            "Epoch 356/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9064 - mae: 1.9556 - val_loss: 40.8573 - val_mae: 43.4595\n",
            "Epoch 357/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9029 - mae: 1.9471 - val_loss: 40.5281 - val_mae: 43.1178\n",
            "Epoch 358/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9109 - mae: 1.9568 - val_loss: 41.1172 - val_mae: 43.7137\n",
            "Epoch 359/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9005 - mae: 1.9490 - val_loss: 41.0485 - val_mae: 43.6516\n",
            "Epoch 360/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9389 - mae: 1.9496 - val_loss: 41.3570 - val_mae: 43.9650\n",
            "Epoch 361/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.4286 - mae: 1.9497 - val_loss: 41.2175 - val_mae: 43.8302\n",
            "Epoch 362/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9251 - mae: 1.9461 - val_loss: 40.8967 - val_mae: 43.4931\n",
            "Epoch 363/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9415 - mae: 1.9462 - val_loss: 40.9773 - val_mae: 43.5966\n",
            "Epoch 364/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9054 - mae: 1.9443 - val_loss: 41.3156 - val_mae: 43.9351\n",
            "Epoch 365/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9412 - mae: 1.9438 - val_loss: 41.0545 - val_mae: 43.6598\n",
            "Epoch 366/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9035 - mae: 1.9403 - val_loss: 40.8524 - val_mae: 43.4460\n",
            "Epoch 367/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8888 - mae: 1.9372 - val_loss: 40.6663 - val_mae: 43.2507\n",
            "Epoch 368/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8916 - mae: 1.9404 - val_loss: 40.8744 - val_mae: 43.4739\n",
            "Epoch 369/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8800 - mae: 1.9279 - val_loss: 41.5028 - val_mae: 44.1042\n",
            "Epoch 370/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0689 - mae: 1.9478 - val_loss: 40.7755 - val_mae: 43.3649\n",
            "Epoch 371/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9151 - mae: 1.9337 - val_loss: 40.8232 - val_mae: 43.4087\n",
            "Epoch 372/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8885 - mae: 1.9351 - val_loss: 40.6823 - val_mae: 43.2602\n",
            "Epoch 373/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8848 - mae: 1.9326 - val_loss: 40.7908 - val_mae: 43.3773\n",
            "Epoch 374/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9055 - mae: 1.9290 - val_loss: 40.6492 - val_mae: 43.2218\n",
            "Epoch 375/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9272 - mae: 1.9294 - val_loss: 41.1105 - val_mae: 43.7104\n",
            "Epoch 376/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.1360 - mae: 1.9343 - val_loss: 40.7153 - val_mae: 43.2974\n",
            "Epoch 377/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8919 - mae: 1.9201 - val_loss: 40.6329 - val_mae: 43.2016\n",
            "Epoch 378/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9447 - mae: 1.9240 - val_loss: 40.8298 - val_mae: 43.4245\n",
            "Epoch 379/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8708 - mae: 1.9171 - val_loss: 41.2533 - val_mae: 43.8642\n",
            "Epoch 380/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8907 - mae: 1.9227 - val_loss: 40.6568 - val_mae: 43.2264\n",
            "Epoch 381/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9175 - mae: 1.9198 - val_loss: 40.8024 - val_mae: 43.3906\n",
            "Epoch 382/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8636 - mae: 1.9114 - val_loss: 41.2276 - val_mae: 43.8287\n",
            "Epoch 383/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8797 - mae: 1.9128 - val_loss: 40.8086 - val_mae: 43.3834\n",
            "Epoch 384/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8654 - mae: 1.9101 - val_loss: 40.8424 - val_mae: 43.4332\n",
            "Epoch 385/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8641 - mae: 1.9121 - val_loss: 40.6377 - val_mae: 43.2176\n",
            "Epoch 386/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9349 - mae: 1.9081 - val_loss: 40.8818 - val_mae: 43.4890\n",
            "Epoch 387/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8652 - mae: 1.9060 - val_loss: 41.1129 - val_mae: 43.7148\n",
            "Epoch 388/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8634 - mae: 1.9112 - val_loss: 41.0065 - val_mae: 43.6037\n",
            "Epoch 389/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8584 - mae: 1.9047 - val_loss: 40.7084 - val_mae: 43.2876\n",
            "Epoch 390/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9386 - mae: 1.8987 - val_loss: 41.1111 - val_mae: 43.7102\n",
            "Epoch 391/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.4461 - mae: 1.9000 - val_loss: 41.3918 - val_mae: 44.0061\n",
            "Epoch 392/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9115 - mae: 1.9052 - val_loss: 40.8979 - val_mae: 43.4774\n",
            "Epoch 393/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8467 - mae: 1.8943 - val_loss: 40.7767 - val_mae: 43.3574\n",
            "Epoch 394/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8488 - mae: 1.8962 - val_loss: 41.2125 - val_mae: 43.8138\n",
            "Epoch 395/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8532 - mae: 1.8995 - val_loss: 40.7178 - val_mae: 43.2888\n",
            "Epoch 396/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8449 - mae: 1.8924 - val_loss: 40.6078 - val_mae: 43.1800\n",
            "Epoch 397/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8536 - mae: 1.8930 - val_loss: 40.9845 - val_mae: 43.5861\n",
            "Epoch 398/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1164 - mae: 1.8844 - val_loss: 40.4231 - val_mae: 42.9975\n",
            "Epoch 399/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8772 - mae: 1.8995 - val_loss: 40.7531 - val_mae: 43.3320\n",
            "Epoch 400/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8773 - mae: 1.8875 - val_loss: 41.1297 - val_mae: 43.7139\n",
            "Epoch 401/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8583 - mae: 1.8859 - val_loss: 40.7789 - val_mae: 43.3563\n",
            "Epoch 402/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8328 - mae: 1.8745 - val_loss: 40.6597 - val_mae: 43.2352\n",
            "Epoch 403/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8625 - mae: 1.8820 - val_loss: 41.0073 - val_mae: 43.6140\n",
            "Epoch 404/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8464 - mae: 1.8811 - val_loss: 40.7834 - val_mae: 43.3694\n",
            "Epoch 405/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1103 - mae: 1.8731 - val_loss: 40.9248 - val_mae: 43.5616\n",
            "Epoch 406/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8531 - mae: 1.8846 - val_loss: 41.1027 - val_mae: 43.7163\n",
            "Epoch 407/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8919 - mae: 1.8719 - val_loss: 40.8614 - val_mae: 43.4442\n",
            "Epoch 408/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8695 - mae: 1.8685 - val_loss: 41.0955 - val_mae: 43.7139\n",
            "Epoch 409/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8222 - mae: 1.8652 - val_loss: 40.9823 - val_mae: 43.5827\n",
            "Epoch 410/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8625 - mae: 1.8680 - val_loss: 41.3620 - val_mae: 43.9861\n",
            "Epoch 411/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8370 - mae: 1.8682 - val_loss: 41.2757 - val_mae: 43.9136\n",
            "Epoch 412/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9125 - mae: 1.8605 - val_loss: 41.1941 - val_mae: 43.8025\n",
            "Epoch 413/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8205 - mae: 1.8573 - val_loss: 40.7238 - val_mae: 43.3041\n",
            "Epoch 414/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9061 - mae: 1.8641 - val_loss: 41.3509 - val_mae: 43.9549\n",
            "Epoch 415/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8201 - mae: 1.8606 - val_loss: 41.2644 - val_mae: 43.8864\n",
            "Epoch 416/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8114 - mae: 1.8500 - val_loss: 40.9041 - val_mae: 43.5008\n",
            "Epoch 417/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9204 - mae: 1.8599 - val_loss: 41.3356 - val_mae: 43.9257\n",
            "Epoch 418/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8102 - mae: 1.8564 - val_loss: 40.8486 - val_mae: 43.4246\n",
            "Epoch 419/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8052 - mae: 1.8516 - val_loss: 40.5263 - val_mae: 43.0812\n",
            "Epoch 420/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8787 - mae: 1.8568 - val_loss: 40.7930 - val_mae: 43.3691\n",
            "Epoch 421/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8803 - mae: 1.8481 - val_loss: 40.8832 - val_mae: 43.4747\n",
            "Epoch 422/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8095 - mae: 1.8417 - val_loss: 41.0546 - val_mae: 43.6626\n",
            "Epoch 423/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8046 - mae: 1.8511 - val_loss: 41.0737 - val_mae: 43.6749\n",
            "Epoch 424/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9015 - mae: 1.8452 - val_loss: 41.3112 - val_mae: 43.9462\n",
            "Epoch 425/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8120 - mae: 1.8410 - val_loss: 41.1114 - val_mae: 43.7255\n",
            "Epoch 426/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8345 - mae: 1.8399 - val_loss: 41.5995 - val_mae: 44.2519\n",
            "Epoch 427/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7940 - mae: 1.8387 - val_loss: 41.0275 - val_mae: 43.6234\n",
            "Epoch 428/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7899 - mae: 1.8361 - val_loss: 40.7897 - val_mae: 43.3607\n",
            "Epoch 429/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7981 - mae: 1.8356 - val_loss: 40.9779 - val_mae: 43.5710\n",
            "Epoch 430/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7911 - mae: 1.8352 - val_loss: 41.3110 - val_mae: 43.9150\n",
            "Epoch 431/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7896 - mae: 1.8343 - val_loss: 40.9854 - val_mae: 43.5832\n",
            "Epoch 432/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8040 - mae: 1.8297 - val_loss: 40.8252 - val_mae: 43.3869\n",
            "Epoch 433/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7873 - mae: 1.8328 - val_loss: 41.0857 - val_mae: 43.6796\n",
            "Epoch 434/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7889 - mae: 1.8245 - val_loss: 40.7896 - val_mae: 43.3704\n",
            "Epoch 435/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7936 - mae: 1.8358 - val_loss: 41.0152 - val_mae: 43.5828\n",
            "Epoch 436/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7766 - mae: 1.8224 - val_loss: 41.1808 - val_mae: 43.7878\n",
            "Epoch 437/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8513 - mae: 1.8254 - val_loss: 41.1135 - val_mae: 43.7081\n",
            "Epoch 438/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8609 - mae: 1.8189 - val_loss: 41.1652 - val_mae: 43.7542\n",
            "Epoch 439/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0103 - mae: 1.8243 - val_loss: 40.9271 - val_mae: 43.5385\n",
            "Epoch 440/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7714 - mae: 1.8165 - val_loss: 41.2901 - val_mae: 43.8838\n",
            "Epoch 441/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7743 - mae: 1.8198 - val_loss: 41.0587 - val_mae: 43.6571\n",
            "Epoch 442/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7787 - mae: 1.8102 - val_loss: 40.8237 - val_mae: 43.4053\n",
            "Epoch 443/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7895 - mae: 1.8228 - val_loss: 41.1933 - val_mae: 43.7779\n",
            "Epoch 444/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7658 - mae: 1.8112 - val_loss: 40.8696 - val_mae: 43.4502\n",
            "Epoch 445/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8170 - mae: 1.8102 - val_loss: 41.3562 - val_mae: 43.9507\n",
            "Epoch 446/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8025 - mae: 1.8065 - val_loss: 40.9054 - val_mae: 43.5011\n",
            "Epoch 447/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8001 - mae: 1.8120 - val_loss: 41.3914 - val_mae: 44.0028\n",
            "Epoch 448/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8385 - mae: 1.8127 - val_loss: 40.9546 - val_mae: 43.5287\n",
            "Epoch 449/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8015 - mae: 1.8098 - val_loss: 41.2690 - val_mae: 43.8713\n",
            "Epoch 450/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8990 - mae: 1.8083 - val_loss: 41.1769 - val_mae: 43.7766\n",
            "Epoch 451/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7726 - mae: 1.8019 - val_loss: 40.9735 - val_mae: 43.5814\n",
            "Epoch 452/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7625 - mae: 1.8074 - val_loss: 41.1827 - val_mae: 43.7778\n",
            "Epoch 453/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7560 - mae: 1.7973 - val_loss: 41.3591 - val_mae: 43.9838\n",
            "Epoch 454/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1349 - mae: 1.7934 - val_loss: 41.3350 - val_mae: 43.9441\n",
            "Epoch 455/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8387 - mae: 1.7975 - val_loss: 40.9783 - val_mae: 43.5572\n",
            "Epoch 456/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8024 - mae: 1.7998 - val_loss: 41.1522 - val_mae: 43.7411\n",
            "Epoch 457/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7782 - mae: 1.7999 - val_loss: 41.4035 - val_mae: 44.0396\n",
            "Epoch 458/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7503 - mae: 1.7932 - val_loss: 41.4929 - val_mae: 44.1123\n",
            "Epoch 459/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7527 - mae: 1.7975 - val_loss: 41.3914 - val_mae: 44.0011\n",
            "Epoch 460/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7524 - mae: 1.7942 - val_loss: 41.1344 - val_mae: 43.7317\n",
            "Epoch 461/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7502 - mae: 1.7940 - val_loss: 41.3189 - val_mae: 43.9128\n",
            "Epoch 462/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7882 - mae: 1.7899 - val_loss: 41.6243 - val_mae: 44.2594\n",
            "Epoch 463/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7626 - mae: 1.7814 - val_loss: 41.4979 - val_mae: 44.1040\n",
            "Epoch 464/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9697 - mae: 1.7867 - val_loss: 41.2491 - val_mae: 43.8430\n",
            "Epoch 465/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7469 - mae: 1.7909 - val_loss: 41.2329 - val_mae: 43.8187\n",
            "Epoch 466/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9241 - mae: 1.7794 - val_loss: 41.4780 - val_mae: 44.0882\n",
            "Epoch 467/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7461 - mae: 1.7856 - val_loss: 41.2378 - val_mae: 43.8272\n",
            "Epoch 468/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7336 - mae: 1.7726 - val_loss: 41.7129 - val_mae: 44.3494\n",
            "Epoch 469/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7450 - mae: 1.7851 - val_loss: 41.3521 - val_mae: 43.9449\n",
            "Epoch 470/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7296 - mae: 1.7741 - val_loss: 41.5928 - val_mae: 44.2247\n",
            "Epoch 471/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7611 - mae: 1.7736 - val_loss: 41.7476 - val_mae: 44.3996\n",
            "Epoch 472/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7317 - mae: 1.7737 - val_loss: 41.7966 - val_mae: 44.4305\n",
            "Epoch 473/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7664 - mae: 1.7737 - val_loss: 41.6532 - val_mae: 44.2872\n",
            "Epoch 474/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7521 - mae: 1.7684 - val_loss: 41.8761 - val_mae: 44.5220\n",
            "Epoch 475/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.9532 - mae: 1.7674 - val_loss: 41.5258 - val_mae: 44.1485\n",
            "Epoch 476/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7478 - mae: 1.7730 - val_loss: 41.8443 - val_mae: 44.5002\n",
            "Epoch 477/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7345 - mae: 1.7656 - val_loss: 41.6852 - val_mae: 44.3016\n",
            "Epoch 478/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7899 - mae: 1.7686 - val_loss: 41.3000 - val_mae: 43.9076\n",
            "Epoch 479/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7183 - mae: 1.7626 - val_loss: 41.4167 - val_mae: 44.0395\n",
            "Epoch 480/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8894 - mae: 1.7639 - val_loss: 41.6246 - val_mae: 44.2493\n",
            "Epoch 481/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7165 - mae: 1.7595 - val_loss: 41.5076 - val_mae: 44.1157\n",
            "Epoch 482/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7164 - mae: 1.7519 - val_loss: 41.7429 - val_mae: 44.3688\n",
            "Epoch 483/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7157 - mae: 1.7563 - val_loss: 41.4927 - val_mae: 44.1128\n",
            "Epoch 484/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9883 - mae: 1.7510 - val_loss: 41.2053 - val_mae: 43.8038\n",
            "Epoch 485/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7226 - mae: 1.7658 - val_loss: 41.3663 - val_mae: 43.9867\n",
            "Epoch 486/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7144 - mae: 1.7543 - val_loss: 41.6934 - val_mae: 44.3382\n",
            "Epoch 487/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7015 - mae: 1.7450 - val_loss: 41.9814 - val_mae: 44.6279\n",
            "Epoch 488/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7381 - mae: 1.7432 - val_loss: 41.5699 - val_mae: 44.1727\n",
            "Epoch 489/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7710 - mae: 1.7487 - val_loss: 41.6881 - val_mae: 44.3281\n",
            "Epoch 490/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6982 - mae: 1.7415 - val_loss: 41.5339 - val_mae: 44.1680\n",
            "Epoch 491/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7041 - mae: 1.7396 - val_loss: 41.3223 - val_mae: 43.9084\n",
            "Epoch 492/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7253 - mae: 1.7462 - val_loss: 41.6012 - val_mae: 44.2307\n",
            "Epoch 493/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7129 - mae: 1.7405 - val_loss: 41.8570 - val_mae: 44.4963\n",
            "Epoch 494/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6923 - mae: 1.7359 - val_loss: 41.9952 - val_mae: 44.6289\n",
            "Epoch 495/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7054 - mae: 1.7431 - val_loss: 41.7936 - val_mae: 44.4338\n",
            "Epoch 496/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7012 - mae: 1.7278 - val_loss: 42.0935 - val_mae: 44.7683\n",
            "Epoch 497/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6950 - mae: 1.7387 - val_loss: 41.7881 - val_mae: 44.4506\n",
            "Epoch 498/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6967 - mae: 1.7394 - val_loss: 41.5750 - val_mae: 44.2070\n",
            "Epoch 499/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8779 - mae: 1.7350 - val_loss: 41.8229 - val_mae: 44.4855\n",
            "Epoch 500/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8276 - mae: 1.7328 - val_loss: 41.5123 - val_mae: 44.1398\n",
            "Epoch 501/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7147 - mae: 1.7293 - val_loss: 41.9139 - val_mae: 44.5863\n",
            "Epoch 502/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7040 - mae: 1.7317 - val_loss: 41.6419 - val_mae: 44.2846\n",
            "Epoch 503/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7074 - mae: 1.7289 - val_loss: 41.4733 - val_mae: 44.1061\n",
            "Epoch 504/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7041 - mae: 1.7294 - val_loss: 41.5853 - val_mae: 44.1969\n",
            "Epoch 505/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6895 - mae: 1.7268 - val_loss: 41.5445 - val_mae: 44.1829\n",
            "Epoch 506/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7091 - mae: 1.7292 - val_loss: 41.8656 - val_mae: 44.5170\n",
            "Epoch 507/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6797 - mae: 1.7230 - val_loss: 42.0621 - val_mae: 44.7346\n",
            "Epoch 508/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8484 - mae: 1.7187 - val_loss: 42.0737 - val_mae: 44.7582\n",
            "Epoch 509/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6857 - mae: 1.7260 - val_loss: 42.2182 - val_mae: 44.9050\n",
            "Epoch 510/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7335 - mae: 1.7245 - val_loss: 41.7349 - val_mae: 44.3508\n",
            "Epoch 511/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7865 - mae: 1.7161 - val_loss: 41.7779 - val_mae: 44.4480\n",
            "Epoch 512/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6673 - mae: 1.7103 - val_loss: 41.9289 - val_mae: 44.5752\n",
            "Epoch 513/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7316 - mae: 1.7217 - val_loss: 41.8499 - val_mae: 44.5138\n",
            "Epoch 514/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7114 - mae: 1.7201 - val_loss: 42.1409 - val_mae: 44.8099\n",
            "Epoch 515/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7155 - mae: 1.7249 - val_loss: 41.7189 - val_mae: 44.3443\n",
            "Epoch 516/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7395 - mae: 1.7134 - val_loss: 41.5785 - val_mae: 44.2009\n",
            "Epoch 517/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6789 - mae: 1.7191 - val_loss: 41.7712 - val_mae: 44.4231\n",
            "Epoch 518/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6908 - mae: 1.7187 - val_loss: 41.9077 - val_mae: 44.5394\n",
            "Epoch 519/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6780 - mae: 1.7200 - val_loss: 41.8764 - val_mae: 44.5337\n",
            "Epoch 520/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7673 - mae: 1.7146 - val_loss: 42.1162 - val_mae: 44.7997\n",
            "Epoch 521/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6888 - mae: 1.7135 - val_loss: 41.8845 - val_mae: 44.5509\n",
            "Epoch 522/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6792 - mae: 1.7151 - val_loss: 41.5106 - val_mae: 44.1183\n",
            "Epoch 523/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8431 - mae: 1.7152 - val_loss: 41.8081 - val_mae: 44.4434\n",
            "Epoch 524/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6869 - mae: 1.7151 - val_loss: 41.8431 - val_mae: 44.4751\n",
            "Epoch 525/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6810 - mae: 1.7158 - val_loss: 41.7368 - val_mae: 44.3891\n",
            "Epoch 526/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7085 - mae: 1.7174 - val_loss: 41.7926 - val_mae: 44.4320\n",
            "Epoch 527/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6723 - mae: 1.7104 - val_loss: 41.5979 - val_mae: 44.2203\n",
            "Epoch 528/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7226 - mae: 1.7163 - val_loss: 41.7714 - val_mae: 44.3935\n",
            "Epoch 529/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6761 - mae: 1.7151 - val_loss: 41.7651 - val_mae: 44.4265\n",
            "Epoch 530/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6729 - mae: 1.7072 - val_loss: 41.7346 - val_mae: 44.4035\n",
            "Epoch 531/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6849 - mae: 1.7195 - val_loss: 41.7747 - val_mae: 44.4227\n",
            "Epoch 532/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6624 - mae: 1.7048 - val_loss: 41.6146 - val_mae: 44.2457\n",
            "Epoch 533/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6738 - mae: 1.7162 - val_loss: 41.8391 - val_mae: 44.4851\n",
            "Epoch 534/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7455 - mae: 1.7081 - val_loss: 41.9385 - val_mae: 44.5897\n",
            "Epoch 535/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7312 - mae: 1.7089 - val_loss: 41.7697 - val_mae: 44.4106\n",
            "Epoch 536/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7013 - mae: 1.7056 - val_loss: 41.8551 - val_mae: 44.4869\n",
            "Epoch 537/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6717 - mae: 1.7060 - val_loss: 41.8701 - val_mae: 44.5257\n",
            "Epoch 538/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6608 - mae: 1.7027 - val_loss: 41.8290 - val_mae: 44.4873\n",
            "Epoch 539/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6786 - mae: 1.7113 - val_loss: 41.9870 - val_mae: 44.6550\n",
            "Epoch 540/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6594 - mae: 1.7014 - val_loss: 42.1440 - val_mae: 44.7991\n",
            "Epoch 541/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8449 - mae: 1.7075 - val_loss: 41.9431 - val_mae: 44.5816\n",
            "Epoch 542/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6652 - mae: 1.7021 - val_loss: 41.8470 - val_mae: 44.5065\n",
            "Epoch 543/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8338 - mae: 1.7038 - val_loss: 42.0047 - val_mae: 44.6590\n",
            "Epoch 544/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7109 - mae: 1.6942 - val_loss: 42.1652 - val_mae: 44.8700\n",
            "Epoch 545/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6770 - mae: 1.7024 - val_loss: 42.0794 - val_mae: 44.7416\n",
            "Epoch 546/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6623 - mae: 1.7023 - val_loss: 41.9324 - val_mae: 44.6010\n",
            "Epoch 547/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6589 - mae: 1.6981 - val_loss: 42.0497 - val_mae: 44.7195\n",
            "Epoch 548/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6585 - mae: 1.7009 - val_loss: 41.8546 - val_mae: 44.4937\n",
            "Epoch 549/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7005 - mae: 1.7038 - val_loss: 41.8558 - val_mae: 44.5181\n",
            "Epoch 550/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6834 - mae: 1.7006 - val_loss: 41.9923 - val_mae: 44.6601\n",
            "Epoch 551/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6585 - mae: 1.6984 - val_loss: 42.0013 - val_mae: 44.6698\n",
            "Epoch 552/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6576 - mae: 1.7000 - val_loss: 42.0152 - val_mae: 44.6719\n",
            "Epoch 553/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6790 - mae: 1.6956 - val_loss: 42.5248 - val_mae: 45.2556\n",
            "Epoch 554/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6459 - mae: 1.6861 - val_loss: 41.9440 - val_mae: 44.5695\n",
            "Epoch 555/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6470 - mae: 1.6889 - val_loss: 41.9291 - val_mae: 44.6066\n",
            "Epoch 556/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7432 - mae: 1.7033 - val_loss: 42.2249 - val_mae: 44.9209\n",
            "Epoch 557/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6537 - mae: 1.6963 - val_loss: 42.2493 - val_mae: 44.9291\n",
            "Epoch 558/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6650 - mae: 1.6957 - val_loss: 42.0242 - val_mae: 44.6807\n",
            "Epoch 559/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7118 - mae: 1.6946 - val_loss: 42.3580 - val_mae: 45.0428\n",
            "Epoch 560/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7171 - mae: 1.6945 - val_loss: 42.1497 - val_mae: 44.8325\n",
            "Epoch 561/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6563 - mae: 1.6844 - val_loss: 41.7274 - val_mae: 44.3591\n",
            "Epoch 562/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6492 - mae: 1.6916 - val_loss: 42.3130 - val_mae: 45.0049\n",
            "Epoch 563/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8118 - mae: 1.6923 - val_loss: 42.4027 - val_mae: 45.0852\n",
            "Epoch 564/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6482 - mae: 1.6903 - val_loss: 42.3765 - val_mae: 45.0840\n",
            "Epoch 565/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6524 - mae: 1.6929 - val_loss: 42.3731 - val_mae: 45.0457\n",
            "Epoch 566/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6693 - mae: 1.6877 - val_loss: 42.1126 - val_mae: 44.7825\n",
            "Epoch 567/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6431 - mae: 1.6850 - val_loss: 42.4456 - val_mae: 45.1212\n",
            "Epoch 568/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7739 - mae: 1.6886 - val_loss: 42.1705 - val_mae: 44.8228\n",
            "Epoch 569/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6554 - mae: 1.6950 - val_loss: 42.4754 - val_mae: 45.1817\n",
            "Epoch 570/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6466 - mae: 1.6873 - val_loss: 42.3402 - val_mae: 45.0300\n",
            "Epoch 571/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6509 - mae: 1.6839 - val_loss: 42.3947 - val_mae: 45.1017\n",
            "Epoch 572/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6495 - mae: 1.6897 - val_loss: 42.5288 - val_mae: 45.2167\n",
            "Epoch 573/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7404 - mae: 1.6871 - val_loss: 42.5077 - val_mae: 45.2168\n",
            "Epoch 574/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6385 - mae: 1.6807 - val_loss: 42.7626 - val_mae: 45.4868\n",
            "Epoch 575/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6493 - mae: 1.6872 - val_loss: 42.3200 - val_mae: 45.0070\n",
            "Epoch 576/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6796 - mae: 1.6881 - val_loss: 42.4935 - val_mae: 45.2133\n",
            "Epoch 577/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7034 - mae: 1.6884 - val_loss: 42.7341 - val_mae: 45.4621\n",
            "Epoch 578/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6363 - mae: 1.6779 - val_loss: 42.5188 - val_mae: 45.2263\n",
            "Epoch 579/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6615 - mae: 1.6885 - val_loss: 42.5232 - val_mae: 45.2150\n",
            "Epoch 580/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7446 - mae: 1.6817 - val_loss: 42.4375 - val_mae: 45.1051\n",
            "Epoch 581/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6426 - mae: 1.6850 - val_loss: 42.2916 - val_mae: 44.9792\n",
            "Epoch 582/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6458 - mae: 1.6867 - val_loss: 42.5684 - val_mae: 45.2923\n",
            "Epoch 583/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6447 - mae: 1.6813 - val_loss: 42.1063 - val_mae: 44.7551\n",
            "Epoch 584/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6405 - mae: 1.6823 - val_loss: 42.2642 - val_mae: 44.9636\n",
            "Epoch 585/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6673 - mae: 1.6859 - val_loss: 42.4252 - val_mae: 45.1225\n",
            "Epoch 586/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6454 - mae: 1.6765 - val_loss: 42.5785 - val_mae: 45.2888\n",
            "Epoch 587/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6872 - mae: 1.6753 - val_loss: 42.3914 - val_mae: 45.0778\n",
            "Epoch 588/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6351 - mae: 1.6771 - val_loss: 42.6140 - val_mae: 45.3110\n",
            "Epoch 589/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6695 - mae: 1.6838 - val_loss: 42.5640 - val_mae: 45.2687\n",
            "Epoch 590/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6449 - mae: 1.6804 - val_loss: 42.6243 - val_mae: 45.3464\n",
            "Epoch 591/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6818 - mae: 1.6775 - val_loss: 42.3492 - val_mae: 45.0461\n",
            "Epoch 592/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6565 - mae: 1.6809 - val_loss: 42.3957 - val_mae: 45.0857\n",
            "Epoch 593/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6421 - mae: 1.6825 - val_loss: 42.5291 - val_mae: 45.2097\n",
            "Epoch 594/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7957 - mae: 1.6794 - val_loss: 42.7641 - val_mae: 45.4819\n",
            "Epoch 595/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6295 - mae: 1.6715 - val_loss: 42.7322 - val_mae: 45.4602\n",
            "Epoch 596/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6384 - mae: 1.6768 - val_loss: 42.6494 - val_mae: 45.3499\n",
            "Epoch 597/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6426 - mae: 1.6747 - val_loss: 42.4272 - val_mae: 45.1006\n",
            "Epoch 598/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6335 - mae: 1.6754 - val_loss: 42.6389 - val_mae: 45.3437\n",
            "Epoch 599/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7938 - mae: 1.6767 - val_loss: 42.6264 - val_mae: 45.3281\n",
            "Epoch 600/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6294 - mae: 1.6702 - val_loss: 42.6363 - val_mae: 45.3408\n",
            "Epoch 601/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8627 - mae: 1.6704 - val_loss: 42.6787 - val_mae: 45.4139\n",
            "Epoch 602/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6440 - mae: 1.6705 - val_loss: 42.7122 - val_mae: 45.4250\n",
            "Epoch 603/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1482 - mae: 1.6724 - val_loss: 42.3596 - val_mae: 45.0475\n",
            "Epoch 604/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8246 - mae: 1.6740 - val_loss: 42.6841 - val_mae: 45.3919\n",
            "Epoch 605/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6512 - mae: 1.6664 - val_loss: 42.6306 - val_mae: 45.3499\n",
            "Epoch 606/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6465 - mae: 1.6735 - val_loss: 42.6799 - val_mae: 45.3832\n",
            "Epoch 607/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6464 - mae: 1.6701 - val_loss: 42.4478 - val_mae: 45.1332\n",
            "Epoch 608/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6311 - mae: 1.6688 - val_loss: 42.7590 - val_mae: 45.4546\n",
            "Epoch 609/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0547 - mae: 1.6706 - val_loss: 42.5564 - val_mae: 45.2538\n",
            "Epoch 610/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7480 - mae: 1.6739 - val_loss: 42.6597 - val_mae: 45.3676\n",
            "Epoch 611/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6620 - mae: 1.6662 - val_loss: 43.0105 - val_mae: 45.7597\n",
            "Epoch 612/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6313 - mae: 1.6671 - val_loss: 42.5458 - val_mae: 45.2422\n",
            "Epoch 613/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6278 - mae: 1.6678 - val_loss: 42.9183 - val_mae: 45.6572\n",
            "Epoch 614/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6312 - mae: 1.6653 - val_loss: 42.5757 - val_mae: 45.2835\n",
            "Epoch 615/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6654 - mae: 1.6671 - val_loss: 42.1722 - val_mae: 44.8254\n",
            "Epoch 616/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7706 - mae: 1.6665 - val_loss: 42.4705 - val_mae: 45.1545\n",
            "Epoch 617/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6317 - mae: 1.6703 - val_loss: 42.4880 - val_mae: 45.2090\n",
            "Epoch 618/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6309 - mae: 1.6726 - val_loss: 42.4682 - val_mae: 45.1736\n",
            "Epoch 619/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7737 - mae: 1.6672 - val_loss: 42.7523 - val_mae: 45.4700\n",
            "Epoch 620/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6466 - mae: 1.6658 - val_loss: 42.5648 - val_mae: 45.2756\n",
            "Epoch 621/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6498 - mae: 1.6682 - val_loss: 42.7105 - val_mae: 45.4267\n",
            "Epoch 622/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6316 - mae: 1.6656 - val_loss: 42.7656 - val_mae: 45.4903\n",
            "Epoch 623/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.1661 - mae: 1.6678 - val_loss: 42.4949 - val_mae: 45.1646\n",
            "Epoch 624/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6318 - mae: 1.6613 - val_loss: 42.3810 - val_mae: 45.0471\n",
            "Epoch 625/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6227 - mae: 1.6635 - val_loss: 42.7191 - val_mae: 45.4296\n",
            "Epoch 626/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6598 - mae: 1.6561 - val_loss: 42.8062 - val_mae: 45.5260\n",
            "Epoch 627/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.6348 - mae: 1.6678 - val_loss: 42.7054 - val_mae: 45.4189\n",
            "Epoch 628/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6208 - mae: 1.6572 - val_loss: 42.8295 - val_mae: 45.5454\n",
            "Epoch 629/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7732 - mae: 1.6675 - val_loss: 42.4912 - val_mae: 45.2020\n",
            "Epoch 630/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6223 - mae: 1.6582 - val_loss: 42.6870 - val_mae: 45.3793\n",
            "Epoch 631/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6190 - mae: 1.6607 - val_loss: 42.5869 - val_mae: 45.3084\n",
            "Epoch 632/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6202 - mae: 1.6579 - val_loss: 42.8460 - val_mae: 45.5676\n",
            "Epoch 633/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6274 - mae: 1.6652 - val_loss: 42.6298 - val_mae: 45.3269\n",
            "Epoch 634/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8166 - mae: 1.6646 - val_loss: 42.8561 - val_mae: 45.5865\n",
            "Epoch 635/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6659 - mae: 1.6592 - val_loss: 43.0000 - val_mae: 45.7213\n",
            "Epoch 636/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6561 - mae: 1.6590 - val_loss: 42.8472 - val_mae: 45.5539\n",
            "Epoch 637/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6872 - mae: 1.6613 - val_loss: 42.7200 - val_mae: 45.4436\n",
            "Epoch 638/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6408 - mae: 1.6588 - val_loss: 42.9974 - val_mae: 45.7482\n",
            "Epoch 639/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6669 - mae: 1.6643 - val_loss: 42.8071 - val_mae: 45.5589\n",
            "Epoch 640/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7951 - mae: 1.6563 - val_loss: 43.0290 - val_mae: 45.7645\n",
            "Epoch 641/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6447 - mae: 1.6578 - val_loss: 42.5687 - val_mae: 45.2517\n",
            "Epoch 642/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6174 - mae: 1.6579 - val_loss: 42.4950 - val_mae: 45.1761\n",
            "Epoch 643/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6811 - mae: 1.6630 - val_loss: 42.8354 - val_mae: 45.5615\n",
            "Epoch 644/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6164 - mae: 1.6497 - val_loss: 43.1663 - val_mae: 45.9285\n",
            "Epoch 645/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6094 - mae: 1.6505 - val_loss: 42.5954 - val_mae: 45.2748\n",
            "Epoch 646/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6572 - mae: 1.6576 - val_loss: 42.7391 - val_mae: 45.4455\n",
            "Epoch 647/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6255 - mae: 1.6597 - val_loss: 42.4810 - val_mae: 45.1607\n",
            "Epoch 648/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6109 - mae: 1.6524 - val_loss: 42.4716 - val_mae: 45.1823\n",
            "Epoch 649/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6377 - mae: 1.6584 - val_loss: 42.6562 - val_mae: 45.3603\n",
            "Epoch 650/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6203 - mae: 1.6557 - val_loss: 42.2717 - val_mae: 44.9393\n",
            "Epoch 651/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6169 - mae: 1.6516 - val_loss: 42.3582 - val_mae: 45.0663\n",
            "Epoch 652/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6947 - mae: 1.6516 - val_loss: 42.5158 - val_mae: 45.1901\n",
            "Epoch 653/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6174 - mae: 1.6577 - val_loss: 42.7469 - val_mae: 45.4720\n",
            "Epoch 654/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6472 - mae: 1.6583 - val_loss: 42.6669 - val_mae: 45.3622\n",
            "Epoch 655/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8801 - mae: 1.6552 - val_loss: 42.8989 - val_mae: 45.6361\n",
            "Epoch 656/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6101 - mae: 1.6515 - val_loss: 42.5756 - val_mae: 45.2831\n",
            "Epoch 657/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6103 - mae: 1.6489 - val_loss: 42.8335 - val_mae: 45.5465\n",
            "Epoch 658/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6730 - mae: 1.6508 - val_loss: 42.5079 - val_mae: 45.1958\n",
            "Epoch 659/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6739 - mae: 1.6592 - val_loss: 42.7312 - val_mae: 45.4356\n",
            "Epoch 660/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6080 - mae: 1.6479 - val_loss: 42.8529 - val_mae: 45.6067\n",
            "Epoch 661/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6107 - mae: 1.6523 - val_loss: 42.7755 - val_mae: 45.4960\n",
            "Epoch 662/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6352 - mae: 1.6520 - val_loss: 42.8255 - val_mae: 45.5526\n",
            "Epoch 663/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6065 - mae: 1.6467 - val_loss: 42.4171 - val_mae: 45.1028\n",
            "Epoch 664/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6481 - mae: 1.6446 - val_loss: 42.7893 - val_mae: 45.5439\n",
            "Epoch 665/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8332 - mae: 1.6619 - val_loss: 42.8818 - val_mae: 45.6207\n",
            "Epoch 666/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6172 - mae: 1.6510 - val_loss: 42.9131 - val_mae: 45.6364\n",
            "Epoch 667/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7611 - mae: 1.6507 - val_loss: 43.0674 - val_mae: 45.8075\n",
            "Epoch 668/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6531 - mae: 1.6563 - val_loss: 42.7309 - val_mae: 45.4395\n",
            "Epoch 669/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6074 - mae: 1.6470 - val_loss: 42.7147 - val_mae: 45.4470\n",
            "Epoch 670/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6102 - mae: 1.6501 - val_loss: 42.7112 - val_mae: 45.4202\n",
            "Epoch 671/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6135 - mae: 1.6546 - val_loss: 42.7415 - val_mae: 45.4705\n",
            "Epoch 672/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6474 - mae: 1.6472 - val_loss: 42.1697 - val_mae: 44.7978\n",
            "Epoch 673/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7817 - mae: 1.6544 - val_loss: 42.5645 - val_mae: 45.2864\n",
            "Epoch 674/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6135 - mae: 1.6519 - val_loss: 42.6837 - val_mae: 45.3826\n",
            "Epoch 675/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6100 - mae: 1.6514 - val_loss: 42.5236 - val_mae: 45.2205\n",
            "Epoch 676/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6483 - mae: 1.6463 - val_loss: 42.2490 - val_mae: 44.9393\n",
            "Epoch 677/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6094 - mae: 1.6500 - val_loss: 42.4893 - val_mae: 45.1791\n",
            "Epoch 678/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6490 - mae: 1.6509 - val_loss: 43.1546 - val_mae: 45.9339\n",
            "Epoch 679/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6229 - mae: 1.6552 - val_loss: 42.7049 - val_mae: 45.4290\n",
            "Epoch 680/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6181 - mae: 1.6493 - val_loss: 42.3970 - val_mae: 45.0835\n",
            "Epoch 681/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6419 - mae: 1.6532 - val_loss: 42.4742 - val_mae: 45.1743\n",
            "Epoch 682/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6239 - mae: 1.6440 - val_loss: 42.9390 - val_mae: 45.6827\n",
            "Epoch 683/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6252 - mae: 1.6583 - val_loss: 42.6660 - val_mae: 45.3754\n",
            "Epoch 684/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6393 - mae: 1.6493 - val_loss: 42.6411 - val_mae: 45.3631\n",
            "Epoch 685/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6106 - mae: 1.6495 - val_loss: 42.7682 - val_mae: 45.4967\n",
            "Epoch 686/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7151 - mae: 1.6384 - val_loss: 42.4702 - val_mae: 45.1547\n",
            "Epoch 687/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6336 - mae: 1.6454 - val_loss: 43.0367 - val_mae: 45.7882\n",
            "Epoch 688/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6217 - mae: 1.6518 - val_loss: 42.8919 - val_mae: 45.6354\n",
            "Epoch 689/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6055 - mae: 1.6469 - val_loss: 42.9123 - val_mae: 45.6327\n",
            "Epoch 690/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6114 - mae: 1.6527 - val_loss: 42.7100 - val_mae: 45.4277\n",
            "Epoch 691/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6097 - mae: 1.6443 - val_loss: 42.4702 - val_mae: 45.1761\n",
            "Epoch 692/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6153 - mae: 1.6457 - val_loss: 42.6521 - val_mae: 45.3577\n",
            "Epoch 693/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6157 - mae: 1.6481 - val_loss: 42.4214 - val_mae: 45.1107\n",
            "Epoch 694/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6142 - mae: 1.6480 - val_loss: 42.7792 - val_mae: 45.4879\n",
            "Epoch 695/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6098 - mae: 1.6398 - val_loss: 42.4784 - val_mae: 45.1788\n",
            "Epoch 696/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6027 - mae: 1.6439 - val_loss: 42.4929 - val_mae: 45.1883\n",
            "Epoch 697/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7391 - mae: 1.6414 - val_loss: 42.5676 - val_mae: 45.2486\n",
            "Epoch 698/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6141 - mae: 1.6460 - val_loss: 43.1011 - val_mae: 45.8631\n",
            "Epoch 699/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5986 - mae: 1.6396 - val_loss: 42.9066 - val_mae: 45.6399\n",
            "Epoch 700/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6162 - mae: 1.6500 - val_loss: 42.7682 - val_mae: 45.4866\n",
            "Epoch 701/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6433 - mae: 1.6407 - val_loss: 42.7667 - val_mae: 45.4831\n",
            "Epoch 702/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6020 - mae: 1.6387 - val_loss: 42.5335 - val_mae: 45.2326\n",
            "Epoch 703/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5973 - mae: 1.6374 - val_loss: 42.9107 - val_mae: 45.6381\n",
            "Epoch 704/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6308 - mae: 1.6403 - val_loss: 42.6855 - val_mae: 45.3994\n",
            "Epoch 705/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6260 - mae: 1.6406 - val_loss: 42.4318 - val_mae: 45.1387\n",
            "Epoch 706/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6145 - mae: 1.6472 - val_loss: 42.6303 - val_mae: 45.3515\n",
            "Epoch 707/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6031 - mae: 1.6410 - val_loss: 42.1061 - val_mae: 44.7445\n",
            "Epoch 708/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6310 - mae: 1.6444 - val_loss: 42.4832 - val_mae: 45.1641\n",
            "Epoch 709/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7022 - mae: 1.6392 - val_loss: 42.7894 - val_mae: 45.5225\n",
            "Epoch 710/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6042 - mae: 1.6450 - val_loss: 42.8352 - val_mae: 45.5628\n",
            "Epoch 711/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6024 - mae: 1.6346 - val_loss: 42.2230 - val_mae: 44.8880\n",
            "Epoch 712/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6048 - mae: 1.6346 - val_loss: 42.6716 - val_mae: 45.3845\n",
            "Epoch 713/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6057 - mae: 1.6385 - val_loss: 42.9912 - val_mae: 45.7255\n",
            "Epoch 714/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0965 - mae: 1.6399 - val_loss: 42.7793 - val_mae: 45.4823\n",
            "Epoch 715/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8077 - mae: 1.6430 - val_loss: 42.6235 - val_mae: 45.3447\n",
            "Epoch 716/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5999 - mae: 1.6407 - val_loss: 42.6171 - val_mae: 45.3129\n",
            "Epoch 717/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5976 - mae: 1.6384 - val_loss: 42.2968 - val_mae: 44.9676\n",
            "Epoch 718/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8209 - mae: 1.6456 - val_loss: 42.8262 - val_mae: 45.5627\n",
            "Epoch 719/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5920 - mae: 1.6329 - val_loss: 42.5344 - val_mae: 45.2050\n",
            "Epoch 720/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6002 - mae: 1.6414 - val_loss: 42.4229 - val_mae: 45.1137\n",
            "Epoch 721/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6077 - mae: 1.6369 - val_loss: 42.6612 - val_mae: 45.3757\n",
            "Epoch 722/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5986 - mae: 1.6385 - val_loss: 42.8042 - val_mae: 45.5034\n",
            "Epoch 723/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6204 - mae: 1.6446 - val_loss: 42.6636 - val_mae: 45.3678\n",
            "Epoch 724/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6222 - mae: 1.6368 - val_loss: 42.7801 - val_mae: 45.4915\n",
            "Epoch 725/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8030 - mae: 1.6308 - val_loss: 42.5208 - val_mae: 45.2040\n",
            "Epoch 726/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6205 - mae: 1.6352 - val_loss: 42.6830 - val_mae: 45.3896\n",
            "Epoch 727/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2.0873 - mae: 1.6395 - val_loss: 42.5911 - val_mae: 45.2884\n",
            "Epoch 728/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6330 - mae: 1.6369 - val_loss: 42.8103 - val_mae: 45.5401\n",
            "Epoch 729/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6029 - mae: 1.6388 - val_loss: 42.5494 - val_mae: 45.2504\n",
            "Epoch 730/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5963 - mae: 1.6294 - val_loss: 42.7940 - val_mae: 45.5012\n",
            "Epoch 731/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6084 - mae: 1.6446 - val_loss: 42.6666 - val_mae: 45.3775\n",
            "Epoch 732/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5928 - mae: 1.6325 - val_loss: 42.8195 - val_mae: 45.5373\n",
            "Epoch 733/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6231 - mae: 1.6391 - val_loss: 42.7124 - val_mae: 45.4141\n",
            "Epoch 734/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6306 - mae: 1.6301 - val_loss: 42.4424 - val_mae: 45.1168\n",
            "Epoch 735/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6054 - mae: 1.6452 - val_loss: 42.5555 - val_mae: 45.2526\n",
            "Epoch 736/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5862 - mae: 1.6267 - val_loss: 42.2984 - val_mae: 45.0043\n",
            "Epoch 737/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6161 - mae: 1.6453 - val_loss: 42.7811 - val_mae: 45.5067\n",
            "Epoch 738/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6483 - mae: 1.6280 - val_loss: 42.6131 - val_mae: 45.2952\n",
            "Epoch 739/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5980 - mae: 1.6392 - val_loss: 42.8401 - val_mae: 45.5697\n",
            "Epoch 740/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7553 - mae: 1.6335 - val_loss: 42.3239 - val_mae: 44.9953\n",
            "Epoch 741/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.9189 - mae: 1.6348 - val_loss: 42.3661 - val_mae: 45.0445\n",
            "Epoch 742/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6387 - mae: 1.6339 - val_loss: 42.5677 - val_mae: 45.2535\n",
            "Epoch 743/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5902 - mae: 1.6310 - val_loss: 42.2011 - val_mae: 44.8605\n",
            "Epoch 744/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6037 - mae: 1.6347 - val_loss: 42.8505 - val_mae: 45.6036\n",
            "Epoch 745/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6010 - mae: 1.6360 - val_loss: 42.3417 - val_mae: 45.0353\n",
            "Epoch 746/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5905 - mae: 1.6314 - val_loss: 42.6910 - val_mae: 45.4000\n",
            "Epoch 747/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6045 - mae: 1.6406 - val_loss: 42.7978 - val_mae: 45.5384\n",
            "Epoch 748/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5880 - mae: 1.6269 - val_loss: 42.8164 - val_mae: 45.5146\n",
            "Epoch 749/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6948 - mae: 1.6394 - val_loss: 42.6992 - val_mae: 45.4142\n",
            "Epoch 750/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6401 - mae: 1.6293 - val_loss: 42.8684 - val_mae: 45.6039\n",
            "Epoch 751/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6107 - mae: 1.6287 - val_loss: 42.6991 - val_mae: 45.4121\n",
            "Epoch 752/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6089 - mae: 1.6331 - val_loss: 42.8750 - val_mae: 45.6091\n",
            "Epoch 753/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6033 - mae: 1.6293 - val_loss: 42.3860 - val_mae: 45.0374\n",
            "Epoch 754/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6044 - mae: 1.6347 - val_loss: 42.9356 - val_mae: 45.6691\n",
            "Epoch 755/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5978 - mae: 1.6325 - val_loss: 42.5313 - val_mae: 45.2348\n",
            "Epoch 756/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5913 - mae: 1.6305 - val_loss: 42.7751 - val_mae: 45.4911\n",
            "Epoch 757/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5888 - mae: 1.6298 - val_loss: 42.7404 - val_mae: 45.4551\n",
            "Epoch 758/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.8120 - mae: 1.6340 - val_loss: 42.5761 - val_mae: 45.2791\n",
            "Epoch 759/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6078 - mae: 1.6337 - val_loss: 42.6796 - val_mae: 45.3962\n",
            "Epoch 760/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6449 - mae: 1.6327 - val_loss: 42.8066 - val_mae: 45.5268\n",
            "Epoch 761/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6557 - mae: 1.6341 - val_loss: 42.9958 - val_mae: 45.7437\n",
            "Epoch 762/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5992 - mae: 1.6224 - val_loss: 43.0974 - val_mae: 45.8461\n",
            "Epoch 763/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6043 - mae: 1.6278 - val_loss: 42.7505 - val_mae: 45.4623\n",
            "Epoch 764/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5946 - mae: 1.6341 - val_loss: 42.5270 - val_mae: 45.2130\n",
            "Epoch 765/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6392 - mae: 1.6324 - val_loss: 42.2688 - val_mae: 44.9498\n",
            "Epoch 766/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6262 - mae: 1.6223 - val_loss: 42.7057 - val_mae: 45.4457\n",
            "Epoch 767/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5999 - mae: 1.6308 - val_loss: 42.7125 - val_mae: 45.4097\n",
            "Epoch 768/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5905 - mae: 1.6310 - val_loss: 42.4462 - val_mae: 45.1386\n",
            "Epoch 769/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5867 - mae: 1.6266 - val_loss: 42.8589 - val_mae: 45.5816\n",
            "Epoch 770/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5847 - mae: 1.6250 - val_loss: 43.0485 - val_mae: 45.7985\n",
            "Epoch 771/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6155 - mae: 1.6308 - val_loss: 42.6076 - val_mae: 45.3204\n",
            "Epoch 772/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5884 - mae: 1.6279 - val_loss: 42.9199 - val_mae: 45.6606\n",
            "Epoch 773/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6178 - mae: 1.6359 - val_loss: 42.8073 - val_mae: 45.5389\n",
            "Epoch 774/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6202 - mae: 1.6241 - val_loss: 42.3307 - val_mae: 45.0316\n",
            "Epoch 775/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6155 - mae: 1.6322 - val_loss: 42.5395 - val_mae: 45.2457\n",
            "Epoch 776/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6428 - mae: 1.6299 - val_loss: 42.5883 - val_mae: 45.3105\n",
            "Epoch 777/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6033 - mae: 1.6296 - val_loss: 42.3640 - val_mae: 45.0562\n",
            "Epoch 778/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6017 - mae: 1.6306 - val_loss: 42.3860 - val_mae: 45.0836\n",
            "Epoch 779/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5949 - mae: 1.6353 - val_loss: 42.3299 - val_mae: 45.0042\n",
            "Epoch 780/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5902 - mae: 1.6304 - val_loss: 42.7449 - val_mae: 45.4734\n",
            "Epoch 781/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5878 - mae: 1.6285 - val_loss: 42.7213 - val_mae: 45.4217\n",
            "Epoch 782/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5860 - mae: 1.6262 - val_loss: 42.4762 - val_mae: 45.1428\n",
            "Epoch 783/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6020 - mae: 1.6261 - val_loss: 42.7169 - val_mae: 45.4394\n",
            "Epoch 784/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5963 - mae: 1.6197 - val_loss: 42.5926 - val_mae: 45.2647\n",
            "Epoch 785/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6357 - mae: 1.6351 - val_loss: 42.5929 - val_mae: 45.2873\n",
            "Epoch 786/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6034 - mae: 1.6318 - val_loss: 42.2765 - val_mae: 44.9483\n",
            "Epoch 787/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5974 - mae: 1.6314 - val_loss: 42.2964 - val_mae: 44.9602\n",
            "Epoch 788/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5878 - mae: 1.6272 - val_loss: 42.6395 - val_mae: 45.3379\n",
            "Epoch 789/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6017 - mae: 1.6294 - val_loss: 42.3661 - val_mae: 45.0420\n",
            "Epoch 790/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6069 - mae: 1.6237 - val_loss: 42.7626 - val_mae: 45.4715\n",
            "Epoch 791/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5847 - mae: 1.6252 - val_loss: 42.8782 - val_mae: 45.6032\n",
            "Epoch 792/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6041 - mae: 1.6294 - val_loss: 42.7311 - val_mae: 45.4526\n",
            "Epoch 793/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5825 - mae: 1.6231 - val_loss: 42.5856 - val_mae: 45.2748\n",
            "Epoch 794/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6503 - mae: 1.6316 - val_loss: 42.6931 - val_mae: 45.4085\n",
            "Epoch 795/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5922 - mae: 1.6231 - val_loss: 42.8395 - val_mae: 45.5619\n",
            "Epoch 796/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5955 - mae: 1.6283 - val_loss: 42.6551 - val_mae: 45.3819\n",
            "Epoch 797/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5859 - mae: 1.6250 - val_loss: 42.3378 - val_mae: 45.0172\n",
            "Epoch 798/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5942 - mae: 1.6256 - val_loss: 42.4665 - val_mae: 45.1444\n",
            "Epoch 799/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0614 - mae: 1.6248 - val_loss: 42.5399 - val_mae: 45.2249\n",
            "Epoch 800/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5964 - mae: 1.6302 - val_loss: 42.3069 - val_mae: 44.9731\n",
            "Epoch 801/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5986 - mae: 1.6244 - val_loss: 42.5260 - val_mae: 45.2244\n",
            "Epoch 802/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6364 - mae: 1.6270 - val_loss: 42.1884 - val_mae: 44.8648\n",
            "Epoch 803/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7757 - mae: 1.6234 - val_loss: 42.4273 - val_mae: 45.1359\n",
            "Epoch 804/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5910 - mae: 1.6232 - val_loss: 42.5872 - val_mae: 45.3039\n",
            "Epoch 805/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5896 - mae: 1.6266 - val_loss: 42.4467 - val_mae: 45.1225\n",
            "Epoch 806/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7224 - mae: 1.6251 - val_loss: 42.2419 - val_mae: 44.9239\n",
            "Epoch 807/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5866 - mae: 1.6271 - val_loss: 42.0471 - val_mae: 44.7100\n",
            "Epoch 808/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6637 - mae: 1.6203 - val_loss: 42.4402 - val_mae: 45.1354\n",
            "Epoch 809/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7797 - mae: 1.6109 - val_loss: 42.6130 - val_mae: 45.3065\n",
            "Epoch 810/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6583 - mae: 1.6260 - val_loss: 42.2816 - val_mae: 44.9624\n",
            "Epoch 811/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6086 - mae: 1.6249 - val_loss: 42.3252 - val_mae: 45.0109\n",
            "Epoch 812/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5790 - mae: 1.6176 - val_loss: 42.1582 - val_mae: 44.8325\n",
            "Epoch 813/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5812 - mae: 1.6216 - val_loss: 42.7326 - val_mae: 45.4632\n",
            "Epoch 814/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6217 - mae: 1.6213 - val_loss: 42.3795 - val_mae: 45.0654\n",
            "Epoch 815/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5822 - mae: 1.6198 - val_loss: 42.3521 - val_mae: 45.0390\n",
            "Epoch 816/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5922 - mae: 1.6248 - val_loss: 42.4247 - val_mae: 45.1036\n",
            "Epoch 817/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5779 - mae: 1.6155 - val_loss: 42.3916 - val_mae: 45.0706\n",
            "Epoch 818/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5970 - mae: 1.6269 - val_loss: 42.3176 - val_mae: 44.9846\n",
            "Epoch 819/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5925 - mae: 1.6233 - val_loss: 42.1065 - val_mae: 44.7707\n",
            "Epoch 820/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5939 - mae: 1.6272 - val_loss: 42.4036 - val_mae: 45.1023\n",
            "Epoch 821/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5775 - mae: 1.6176 - val_loss: 42.6138 - val_mae: 45.3126\n",
            "Epoch 822/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5926 - mae: 1.6224 - val_loss: 42.2792 - val_mae: 44.9541\n",
            "Epoch 823/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6013 - mae: 1.6193 - val_loss: 42.2602 - val_mae: 44.9271\n",
            "Epoch 824/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7461 - mae: 1.6225 - val_loss: 42.2256 - val_mae: 44.9185\n",
            "Epoch 825/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5815 - mae: 1.6202 - val_loss: 42.1976 - val_mae: 44.8514\n",
            "Epoch 826/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6220 - mae: 1.6192 - val_loss: 42.3972 - val_mae: 45.1017\n",
            "Epoch 827/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6566 - mae: 1.6153 - val_loss: 41.8656 - val_mae: 44.4923\n",
            "Epoch 828/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6327 - mae: 1.6263 - val_loss: 42.4637 - val_mae: 45.1888\n",
            "Epoch 829/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5805 - mae: 1.6163 - val_loss: 42.3004 - val_mae: 44.9818\n",
            "Epoch 830/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5874 - mae: 1.6247 - val_loss: 42.2593 - val_mae: 44.9424\n",
            "Epoch 831/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5894 - mae: 1.6162 - val_loss: 42.4282 - val_mae: 45.1079\n",
            "Epoch 832/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6300 - mae: 1.6214 - val_loss: 42.3164 - val_mae: 44.9965\n",
            "Epoch 833/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5775 - mae: 1.6181 - val_loss: 42.4758 - val_mae: 45.1579\n",
            "Epoch 834/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6955 - mae: 1.6166 - val_loss: 42.2508 - val_mae: 44.9164\n",
            "Epoch 835/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6175 - mae: 1.6191 - val_loss: 42.3115 - val_mae: 44.9824\n",
            "Epoch 836/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5874 - mae: 1.6178 - val_loss: 41.8807 - val_mae: 44.5211\n",
            "Epoch 837/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6462 - mae: 1.6185 - val_loss: 42.2300 - val_mae: 44.8843\n",
            "Epoch 838/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5958 - mae: 1.6229 - val_loss: 42.0892 - val_mae: 44.7556\n",
            "Epoch 839/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5906 - mae: 1.6219 - val_loss: 42.4132 - val_mae: 45.0980\n",
            "Epoch 840/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5777 - mae: 1.6177 - val_loss: 42.3127 - val_mae: 44.9841\n",
            "Epoch 841/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5778 - mae: 1.6174 - val_loss: 41.8557 - val_mae: 44.4873\n",
            "Epoch 842/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5979 - mae: 1.6207 - val_loss: 42.2789 - val_mae: 44.9466\n",
            "Epoch 843/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5753 - mae: 1.6144 - val_loss: 41.9778 - val_mae: 44.6228\n",
            "Epoch 844/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6017 - mae: 1.6220 - val_loss: 42.0579 - val_mae: 44.7107\n",
            "Epoch 845/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5770 - mae: 1.6176 - val_loss: 42.0684 - val_mae: 44.7282\n",
            "Epoch 846/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6291 - mae: 1.6187 - val_loss: 42.4436 - val_mae: 45.1467\n",
            "Epoch 847/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7590 - mae: 1.6193 - val_loss: 41.9879 - val_mae: 44.6431\n",
            "Epoch 848/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7567 - mae: 1.6144 - val_loss: 42.1493 - val_mae: 44.8109\n",
            "Epoch 849/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5829 - mae: 1.6157 - val_loss: 41.8841 - val_mae: 44.5259\n",
            "Epoch 850/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5876 - mae: 1.6192 - val_loss: 42.3930 - val_mae: 45.0774\n",
            "Epoch 851/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5743 - mae: 1.6149 - val_loss: 42.2216 - val_mae: 44.8867\n",
            "Epoch 852/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5963 - mae: 1.6157 - val_loss: 42.5006 - val_mae: 45.2047\n",
            "Epoch 853/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5768 - mae: 1.6175 - val_loss: 42.0660 - val_mae: 44.7400\n",
            "Epoch 854/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5874 - mae: 1.6145 - val_loss: 42.1798 - val_mae: 44.8396\n",
            "Epoch 855/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6052 - mae: 1.6222 - val_loss: 42.0941 - val_mae: 44.7695\n",
            "Epoch 856/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5828 - mae: 1.6143 - val_loss: 42.1729 - val_mae: 44.8281\n",
            "Epoch 857/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5866 - mae: 1.6162 - val_loss: 42.1113 - val_mae: 44.7810\n",
            "Epoch 858/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7125 - mae: 1.6096 - val_loss: 42.4544 - val_mae: 45.1560\n",
            "Epoch 859/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5947 - mae: 1.6130 - val_loss: 42.5859 - val_mae: 45.2875\n",
            "Epoch 860/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5825 - mae: 1.6232 - val_loss: 42.4205 - val_mae: 45.1098\n",
            "Epoch 861/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6011 - mae: 1.6154 - val_loss: 42.3363 - val_mae: 45.0024\n",
            "Epoch 862/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5791 - mae: 1.6154 - val_loss: 42.2443 - val_mae: 44.9174\n",
            "Epoch 863/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6076 - mae: 1.6132 - val_loss: 42.4956 - val_mae: 45.1859\n",
            "Epoch 864/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5730 - mae: 1.6133 - val_loss: 42.1571 - val_mae: 44.8216\n",
            "Epoch 865/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5787 - mae: 1.6194 - val_loss: 42.2940 - val_mae: 44.9734\n",
            "Epoch 866/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5736 - mae: 1.6130 - val_loss: 42.3023 - val_mae: 44.9826\n",
            "Epoch 867/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5954 - mae: 1.6189 - val_loss: 42.3273 - val_mae: 45.0054\n",
            "Epoch 868/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5810 - mae: 1.6171 - val_loss: 42.0980 - val_mae: 44.7641\n",
            "Epoch 869/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7582 - mae: 1.6100 - val_loss: 42.0296 - val_mae: 44.7035\n",
            "Epoch 870/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5857 - mae: 1.6138 - val_loss: 42.3595 - val_mae: 45.0532\n",
            "Epoch 871/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5819 - mae: 1.6179 - val_loss: 41.8617 - val_mae: 44.4838\n",
            "Epoch 872/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5695 - mae: 1.6065 - val_loss: 42.5057 - val_mae: 45.1907\n",
            "Epoch 873/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5760 - mae: 1.6160 - val_loss: 42.3978 - val_mae: 45.0947\n",
            "Epoch 874/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5806 - mae: 1.6153 - val_loss: 42.0366 - val_mae: 44.7020\n",
            "Epoch 875/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5849 - mae: 1.6149 - val_loss: 42.4265 - val_mae: 45.1163\n",
            "Epoch 876/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6066 - mae: 1.6168 - val_loss: 42.3092 - val_mae: 44.9860\n",
            "Epoch 877/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.8121 - mae: 1.6112 - val_loss: 42.4354 - val_mae: 45.1138\n",
            "Epoch 878/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6003 - mae: 1.6174 - val_loss: 42.0491 - val_mae: 44.7040\n",
            "Epoch 879/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5953 - mae: 1.6139 - val_loss: 42.3042 - val_mae: 44.9774\n",
            "Epoch 880/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6145 - mae: 1.6191 - val_loss: 41.9719 - val_mae: 44.6101\n",
            "Epoch 881/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5793 - mae: 1.6153 - val_loss: 42.1809 - val_mae: 44.8419\n",
            "Epoch 882/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5903 - mae: 1.6120 - val_loss: 42.2033 - val_mae: 44.9075\n",
            "Epoch 883/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6166 - mae: 1.6085 - val_loss: 42.4131 - val_mae: 45.0906\n",
            "Epoch 884/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5768 - mae: 1.6169 - val_loss: 42.0481 - val_mae: 44.7104\n",
            "Epoch 885/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5934 - mae: 1.6029 - val_loss: 42.0913 - val_mae: 44.7708\n",
            "Epoch 886/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5918 - mae: 1.6114 - val_loss: 42.1466 - val_mae: 44.8101\n",
            "Epoch 887/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5775 - mae: 1.6181 - val_loss: 42.1852 - val_mae: 44.8596\n",
            "Epoch 888/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5840 - mae: 1.6171 - val_loss: 41.9105 - val_mae: 44.5471\n",
            "Epoch 889/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6426 - mae: 1.6151 - val_loss: 42.0870 - val_mae: 44.7321\n",
            "Epoch 890/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5763 - mae: 1.6077 - val_loss: 42.0858 - val_mae: 44.7370\n",
            "Epoch 891/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5802 - mae: 1.6056 - val_loss: 42.0074 - val_mae: 44.6401\n",
            "Epoch 892/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5828 - mae: 1.6144 - val_loss: 41.7283 - val_mae: 44.3205\n",
            "Epoch 893/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5837 - mae: 1.6180 - val_loss: 41.7887 - val_mae: 44.3910\n",
            "Epoch 894/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6529 - mae: 1.6121 - val_loss: 42.3463 - val_mae: 45.0442\n",
            "Epoch 895/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5987 - mae: 1.6122 - val_loss: 42.0358 - val_mae: 44.7045\n",
            "Epoch 896/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6138 - mae: 1.6145 - val_loss: 41.9249 - val_mae: 44.5695\n",
            "Epoch 897/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6348 - mae: 1.6099 - val_loss: 41.9679 - val_mae: 44.6439\n",
            "Epoch 898/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5770 - mae: 1.6093 - val_loss: 42.2505 - val_mae: 44.9442\n",
            "Epoch 899/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6978 - mae: 1.6156 - val_loss: 41.9813 - val_mae: 44.6445\n",
            "Epoch 900/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5791 - mae: 1.6105 - val_loss: 42.0486 - val_mae: 44.6943\n",
            "Epoch 901/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5720 - mae: 1.6055 - val_loss: 42.0407 - val_mae: 44.6840\n",
            "Epoch 902/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2.0745 - mae: 1.6107 - val_loss: 42.2140 - val_mae: 44.8709\n",
            "Epoch 903/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5655 - mae: 1.6056 - val_loss: 41.9658 - val_mae: 44.6260\n",
            "Epoch 904/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5667 - mae: 1.5998 - val_loss: 41.8669 - val_mae: 44.4769\n",
            "Epoch 905/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5934 - mae: 1.6231 - val_loss: 42.2708 - val_mae: 44.9928\n",
            "Epoch 906/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5882 - mae: 1.6157 - val_loss: 41.8677 - val_mae: 44.5249\n",
            "Epoch 907/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5800 - mae: 1.6164 - val_loss: 42.3078 - val_mae: 45.0177\n",
            "Epoch 908/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5772 - mae: 1.6101 - val_loss: 41.7385 - val_mae: 44.3639\n",
            "Epoch 909/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5745 - mae: 1.6097 - val_loss: 42.1794 - val_mae: 44.8652\n",
            "Epoch 910/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5791 - mae: 1.6118 - val_loss: 41.8065 - val_mae: 44.4692\n",
            "Epoch 911/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5719 - mae: 1.6125 - val_loss: 41.9500 - val_mae: 44.6043\n",
            "Epoch 912/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6027 - mae: 1.6073 - val_loss: 41.8325 - val_mae: 44.4931\n",
            "Epoch 913/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5706 - mae: 1.6103 - val_loss: 41.8025 - val_mae: 44.4427\n",
            "Epoch 914/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5919 - mae: 1.6070 - val_loss: 42.2639 - val_mae: 44.9613\n",
            "Epoch 915/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5724 - mae: 1.6101 - val_loss: 41.8737 - val_mae: 44.5102\n",
            "Epoch 916/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5704 - mae: 1.6023 - val_loss: 41.7748 - val_mae: 44.4205\n",
            "Epoch 917/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5745 - mae: 1.6032 - val_loss: 42.0003 - val_mae: 44.6484\n",
            "Epoch 918/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5843 - mae: 1.6133 - val_loss: 42.2415 - val_mae: 44.9357\n",
            "Epoch 919/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5916 - mae: 1.6149 - val_loss: 41.9593 - val_mae: 44.6064\n",
            "Epoch 920/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5994 - mae: 1.6034 - val_loss: 41.8372 - val_mae: 44.4355\n",
            "Epoch 921/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5749 - mae: 1.6155 - val_loss: 41.7243 - val_mae: 44.3438\n",
            "Epoch 922/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5714 - mae: 1.6098 - val_loss: 41.5751 - val_mae: 44.1774\n",
            "Epoch 923/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5747 - mae: 1.6049 - val_loss: 41.7312 - val_mae: 44.3644\n",
            "Epoch 924/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6126 - mae: 1.6069 - val_loss: 42.2859 - val_mae: 45.0002\n",
            "Epoch 925/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5714 - mae: 1.6119 - val_loss: 41.7679 - val_mae: 44.4176\n",
            "Epoch 926/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5616 - mae: 1.6013 - val_loss: 41.7147 - val_mae: 44.3461\n",
            "Epoch 927/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6008 - mae: 1.6111 - val_loss: 41.6955 - val_mae: 44.3269\n",
            "Epoch 928/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6168 - mae: 1.6045 - val_loss: 41.9516 - val_mae: 44.6002\n",
            "Epoch 929/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5735 - mae: 1.6030 - val_loss: 42.0321 - val_mae: 44.6670\n",
            "Epoch 930/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5860 - mae: 1.6172 - val_loss: 42.0571 - val_mae: 44.7272\n",
            "Epoch 931/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5756 - mae: 1.6066 - val_loss: 41.7018 - val_mae: 44.3284\n",
            "Epoch 932/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5788 - mae: 1.6088 - val_loss: 41.9525 - val_mae: 44.5993\n",
            "Epoch 933/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5640 - mae: 1.6043 - val_loss: 42.1877 - val_mae: 44.8591\n",
            "Epoch 934/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.7562 - mae: 1.6106 - val_loss: 41.8088 - val_mae: 44.4171\n",
            "Epoch 935/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5912 - mae: 1.6032 - val_loss: 41.7565 - val_mae: 44.3962\n",
            "Epoch 936/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6969 - mae: 1.5931 - val_loss: 41.9753 - val_mae: 44.6295\n",
            "Epoch 937/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7538 - mae: 1.6115 - val_loss: 41.9116 - val_mae: 44.5742\n",
            "Epoch 938/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5688 - mae: 1.6058 - val_loss: 42.0901 - val_mae: 44.7680\n",
            "Epoch 939/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5635 - mae: 1.6034 - val_loss: 41.9795 - val_mae: 44.6264\n",
            "Epoch 940/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5668 - mae: 1.5989 - val_loss: 42.1294 - val_mae: 44.7940\n",
            "Epoch 941/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5934 - mae: 1.6156 - val_loss: 41.8174 - val_mae: 44.4579\n",
            "Epoch 942/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5611 - mae: 1.6014 - val_loss: 41.5521 - val_mae: 44.1669\n",
            "Epoch 943/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6020 - mae: 1.6108 - val_loss: 41.8968 - val_mae: 44.5476\n",
            "Epoch 944/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5617 - mae: 1.6017 - val_loss: 41.9569 - val_mae: 44.6243\n",
            "Epoch 945/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6115 - mae: 1.6032 - val_loss: 41.8549 - val_mae: 44.5082\n",
            "Epoch 946/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5620 - mae: 1.6022 - val_loss: 41.8126 - val_mae: 44.4350\n",
            "Epoch 947/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5743 - mae: 1.6064 - val_loss: 41.7381 - val_mae: 44.3656\n",
            "Epoch 948/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5810 - mae: 1.6103 - val_loss: 41.9862 - val_mae: 44.6325\n",
            "Epoch 949/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5679 - mae: 1.6082 - val_loss: 41.7190 - val_mae: 44.3480\n",
            "Epoch 950/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5736 - mae: 1.6143 - val_loss: 42.1005 - val_mae: 44.7716\n",
            "Epoch 951/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5678 - mae: 1.6022 - val_loss: 41.9228 - val_mae: 44.5937\n",
            "Epoch 952/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5595 - mae: 1.5995 - val_loss: 41.9303 - val_mae: 44.5610\n",
            "Epoch 953/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5669 - mae: 1.6069 - val_loss: 41.6352 - val_mae: 44.2456\n",
            "Epoch 954/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5772 - mae: 1.6056 - val_loss: 41.7668 - val_mae: 44.3818\n",
            "Epoch 955/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5914 - mae: 1.6009 - val_loss: 42.0084 - val_mae: 44.6811\n",
            "Epoch 956/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5818 - mae: 1.6082 - val_loss: 41.8333 - val_mae: 44.4483\n",
            "Epoch 957/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5713 - mae: 1.6096 - val_loss: 41.6923 - val_mae: 44.3222\n",
            "Epoch 958/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5981 - mae: 1.6058 - val_loss: 41.8408 - val_mae: 44.4756\n",
            "Epoch 959/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5676 - mae: 1.6048 - val_loss: 41.9640 - val_mae: 44.6171\n",
            "Epoch 960/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5670 - mae: 1.6073 - val_loss: 41.7320 - val_mae: 44.3691\n",
            "Epoch 961/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6061 - mae: 1.6023 - val_loss: 41.4334 - val_mae: 44.0336\n",
            "Epoch 962/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5756 - mae: 1.5998 - val_loss: 41.9443 - val_mae: 44.5902\n",
            "Epoch 963/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5592 - mae: 1.5992 - val_loss: 41.5695 - val_mae: 44.1883\n",
            "Epoch 964/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5748 - mae: 1.6072 - val_loss: 41.8673 - val_mae: 44.5226\n",
            "Epoch 965/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5670 - mae: 1.6021 - val_loss: 41.6774 - val_mae: 44.3349\n",
            "Epoch 966/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5681 - mae: 1.6083 - val_loss: 41.6542 - val_mae: 44.2686\n",
            "Epoch 967/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6090 - mae: 1.6049 - val_loss: 41.7279 - val_mae: 44.3948\n",
            "Epoch 968/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5691 - mae: 1.6001 - val_loss: 41.2750 - val_mae: 43.8415\n",
            "Epoch 969/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6175 - mae: 1.5929 - val_loss: 41.5867 - val_mae: 44.2170\n",
            "Epoch 970/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5685 - mae: 1.6084 - val_loss: 41.6372 - val_mae: 44.2618\n",
            "Epoch 971/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5646 - mae: 1.6046 - val_loss: 41.9890 - val_mae: 44.6711\n",
            "Epoch 972/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5675 - mae: 1.6078 - val_loss: 41.9569 - val_mae: 44.6071\n",
            "Epoch 973/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5823 - mae: 1.6067 - val_loss: 41.8849 - val_mae: 44.5432\n",
            "Epoch 974/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5837 - mae: 1.6043 - val_loss: 41.7120 - val_mae: 44.3532\n",
            "Epoch 975/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5704 - mae: 1.6049 - val_loss: 41.9986 - val_mae: 44.6724\n",
            "Epoch 976/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5944 - mae: 1.5999 - val_loss: 42.0034 - val_mae: 44.6513\n",
            "Epoch 977/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5904 - mae: 1.6058 - val_loss: 41.8115 - val_mae: 44.4702\n",
            "Epoch 978/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5579 - mae: 1.5981 - val_loss: 41.7664 - val_mae: 44.3704\n",
            "Epoch 979/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6143 - mae: 1.6050 - val_loss: 41.8547 - val_mae: 44.5147\n",
            "Epoch 980/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5639 - mae: 1.6041 - val_loss: 41.7548 - val_mae: 44.3678\n",
            "Epoch 981/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6530 - mae: 1.5999 - val_loss: 41.9679 - val_mae: 44.6250\n",
            "Epoch 982/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5973 - mae: 1.6041 - val_loss: 41.6551 - val_mae: 44.2910\n",
            "Epoch 983/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7834 - mae: 1.5996 - val_loss: 42.0294 - val_mae: 44.6891\n",
            "Epoch 984/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5617 - mae: 1.5986 - val_loss: 42.2106 - val_mae: 44.8743\n",
            "Epoch 985/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6611 - mae: 1.6035 - val_loss: 41.7286 - val_mae: 44.3312\n",
            "Epoch 986/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6104 - mae: 1.5958 - val_loss: 41.7032 - val_mae: 44.3585\n",
            "Epoch 987/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5626 - mae: 1.6018 - val_loss: 41.8147 - val_mae: 44.4451\n",
            "Epoch 988/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5810 - mae: 1.6127 - val_loss: 41.7978 - val_mae: 44.4392\n",
            "Epoch 989/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.6116 - mae: 1.5947 - val_loss: 41.9223 - val_mae: 44.5544\n",
            "Epoch 990/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5848 - mae: 1.6085 - val_loss: 41.9047 - val_mae: 44.5538\n",
            "Epoch 991/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.6888 - mae: 1.6028 - val_loss: 41.6233 - val_mae: 44.2464\n",
            "Epoch 992/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5824 - mae: 1.6000 - val_loss: 41.8639 - val_mae: 44.5044\n",
            "Epoch 993/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5716 - mae: 1.6032 - val_loss: 41.7103 - val_mae: 44.3493\n",
            "Epoch 994/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5639 - mae: 1.6032 - val_loss: 41.8857 - val_mae: 44.5402\n",
            "Epoch 995/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5809 - mae: 1.5977 - val_loss: 41.5471 - val_mae: 44.1613\n",
            "Epoch 996/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.7333 - mae: 1.5953 - val_loss: 41.8813 - val_mae: 44.5192\n",
            "Epoch 997/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5649 - mae: 1.6018 - val_loss: 41.6142 - val_mae: 44.2350\n",
            "Epoch 998/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5665 - mae: 1.6027 - val_loss: 41.6999 - val_mae: 44.3186\n",
            "Epoch 999/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 1.5872 - mae: 1.5985 - val_loss: 42.0931 - val_mae: 44.7480\n",
            "Epoch 1000/1000\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 1.5691 - mae: 1.6049 - val_loss: 41.6470 - val_mae: 44.2705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkvaAnqv8zRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "1c564872-82b8-45b7-994c-07e87e4e3135"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Check what's in the history\n",
        "print(thing.params)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "plt.plot(thing.history['mae']) # replace with accuracy/MAE\n",
        "plt.plot(thing.history['val_mae']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'verbose': 1, 'epochs': 1000, 'steps': 36}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcziwLRt-Mgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ac5ae8a2-4c3a-4061-cca6-6b3797d446b3"
      },
      "source": [
        "# base\n",
        "index_30percent = int(0.3 * len(dataset[:, 0]))\n",
        "print(index_30percent)\n",
        "print(int(len(dataset[:, 0])))\n",
        "# Split into training and validation\n",
        "XVALID = dataset[:index_30percent, [0, 1, 2, 3, 4, 5]]\n",
        "YVALID = dataset[:index_30percent, 6]\n",
        "XTRAIN = dataset[index_30percent:, [0, 1, 2, 3, 4, 5]]\n",
        "YTRAIN = dataset[index_30percent:, 6]\n",
        "mean = XTRAIN.mean(axis = 0)\n",
        "XTRAIN -= mean\n",
        "std = XTRAIN.std(axis = 0)\n",
        "XTRAIN /= std\n",
        "XVALID -= mean\n",
        "XVALID /= std\n",
        "# File name must be in quotes\n",
        "callback_a = ModelCheckpoint(filepath = \"model\", monitor='val_loss', save_best_only = True, save_weights_only = True, verbose = 1)\n",
        "# The patience value can be 10, 20, 100, etc. depending on when your model starts to overfit\n",
        "callback_b = EarlyStopping(monitor='val_loss', mode='min', patience=400, verbose=1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "481\n",
            "1604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbXAQufJ9QuE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "27d0eaa5-9e51-49f8-8243-673cbf579bf2"
      },
      "source": [
        "history = model.fit(XTRAIN, YTRAIN, validation_data=(XVALID, YVALID), epochs=10, batch_size=1, callbacks = [callback_a, callback_b])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1103/1123 [============================>.] - ETA: 0s - loss: 1.6470 - mae: 1.6470\n",
            "Epoch 00001: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.6656 - mae: 1.6656 - val_loss: 43.1366 - val_mae: 43.1366\n",
            "Epoch 2/10\n",
            "1114/1123 [============================>.] - ETA: 0s - loss: 1.6942 - mae: 1.6942\n",
            "Epoch 00002: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.6927 - mae: 1.6927 - val_loss: 43.2088 - val_mae: 43.2088\n",
            "Epoch 3/10\n",
            "1107/1123 [============================>.] - ETA: 0s - loss: 1.6762 - mae: 1.6762\n",
            "Epoch 00003: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.6747 - mae: 1.6747 - val_loss: 43.0031 - val_mae: 43.0031\n",
            "Epoch 4/10\n",
            "1101/1123 [============================>.] - ETA: 0s - loss: 1.6741 - mae: 1.6741\n",
            "Epoch 00004: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.6775 - mae: 1.6775 - val_loss: 43.5992 - val_mae: 43.5992\n",
            "Epoch 5/10\n",
            "1100/1123 [============================>.] - ETA: 0s - loss: 1.6622 - mae: 1.6622\n",
            "Epoch 00005: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.6914 - mae: 1.6914 - val_loss: 43.5858 - val_mae: 43.5858\n",
            "Epoch 6/10\n",
            "1102/1123 [============================>.] - ETA: 0s - loss: 1.6438 - mae: 1.6438\n",
            "Epoch 00006: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.6979 - mae: 1.6979 - val_loss: 43.2486 - val_mae: 43.2486\n",
            "Epoch 7/10\n",
            "1121/1123 [============================>.] - ETA: 0s - loss: 1.6978 - mae: 1.6978\n",
            "Epoch 00007: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.6957 - mae: 1.6957 - val_loss: 43.3892 - val_mae: 43.3892\n",
            "Epoch 8/10\n",
            "1098/1123 [============================>.] - ETA: 0s - loss: 1.6610 - mae: 1.6610\n",
            "Epoch 00008: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.7052 - mae: 1.7052 - val_loss: 42.5554 - val_mae: 42.5554\n",
            "Epoch 9/10\n",
            "1115/1123 [============================>.] - ETA: 0s - loss: 1.7030 - mae: 1.7030\n",
            "Epoch 00009: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.6989 - mae: 1.6989 - val_loss: 42.7151 - val_mae: 42.7151\n",
            "Epoch 10/10\n",
            "1090/1123 [============================>.] - ETA: 0s - loss: 1.7399 - mae: 1.7399\n",
            "Epoch 00010: val_loss did not improve from 41.82034\n",
            "1123/1123 [==============================] - 2s 2ms/step - loss: 1.7110 - mae: 1.7110 - val_loss: 42.2333 - val_mae: 42.2333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQwsgjPzAF7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "b42b52bc-05e7-4c54-b224-b16056b9a921"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Check what's in the history\n",
        "print(history.params)\n",
        "# Plot the learning curves (loss/accuracy/MAE)\n",
        "model.load_weights(\"model\")\n",
        "plt.plot(history.history['loss']) # replace with accuracy/MAE\n",
        "plt.plot(history.history['val_loss']) # replace with val_accuracy, etc.\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training data', 'validation data'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'verbose': 1, 'epochs': 10, 'steps': 1123}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "970haFWmGhT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shows that val loss did not improve beyond ~42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EylCWdj8GoVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a) At 1000 epochs the normal method takes about 1 minute, with early stopping it takes about 3 seconds\n",
        "# b) Without model checkpointing the mae was an average of 1.61 while with model checkpointing it's\n",
        "# average was about 1.69 so actually slightly higher with."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}